{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Sentinel-1 RTC products from different software"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was produced as part of the Digital Earth Antarctica (DEAnt) evaluation of different software options to produce SAR RTC data. Four options have been compares using 'on-the-fly' (otf) pipelines developed for each software. The four softwares options of interest are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import json\n",
    "import rasterio\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.enums import Resampling\n",
    "import rioxarray\n",
    "import asf_search as asf\n",
    "from shapely.geometry import Polygon\n",
    "from celluloid import Camera # getting the camera\n",
    "from IPython.display import HTML\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gif(imgs, vmin, vmax, title=''):\n",
    "    fig, ax = plt.subplots() # make it bigger\n",
    "    camera = Camera(fig)# the camera gets our figure\n",
    "    for i,img in enumerate(imgs):\n",
    "        im = ax.imshow(img,\n",
    "                  vmin=vmin,\n",
    "                  vmax=vmax) # plotting\n",
    "        ax.set_title(f'{title}')\n",
    "        camera.snap()\n",
    "    animation = camera.animate()\n",
    "    return animation\n",
    "\n",
    "def assign_crs(tif_path, crs):\n",
    "    with rasterio.open(tif_path, 'r+') as rds:\n",
    "        print(f'existing crs: {rds.crs}')\n",
    "        rds.crs = CRS.from_epsg(crs)\n",
    "        print(f'assigned crs: {rds.crs}')\n",
    "\n",
    "\n",
    "def plot_tifs(\n",
    "    tif_1, \n",
    "    tif_2, \n",
    "    titles= ['arr_1', 'arr_2'],\n",
    "    suptitle='suptitle',\n",
    "    convert_dB = True,\n",
    "    scale=[-40,10],\n",
    "    cmap = 'binary_r',\n",
    "    save_path=''):\n",
    "\n",
    "    # place to store data\n",
    "    hist_data, crss, meta = [],[], []\n",
    "    colors = ['red', 'blue']\n",
    "\n",
    "    # plot the tif\n",
    "    f, ax = plt.subplots(nrows=1, ncols=2, figsize=(18,10))\n",
    "    for i, tif in enumerate([tif_1, tif_2]):\n",
    "        with rasterio.open(tif) as src:\n",
    "                data = src.read(1)\n",
    "                nodata = src.nodata\n",
    "                # covert from linear to db\n",
    "                if convert_dB:\n",
    "                    data = 10*np.log10(data)\n",
    "                # covert no data to nan\n",
    "                data[data==nodata] = np.nan\n",
    "                crss.append(src.meta['crs'])\n",
    "                im = ax[i].imshow(data, cmap=cmap, vmin=scale[0], vmax=scale[1])\n",
    "                ax[i].set_title(f'{titles[i]}')\n",
    "                hist_data.append(data[(np.isfinite(data))])\n",
    "                meta.append(src.meta.copy())\n",
    "\n",
    "    plt.suptitle(f'{suptitle}', y=0.9)\n",
    "    cbar_ax = f.add_axes([0.95, 0.15, 0.04, 0.7])\n",
    "    f.colorbar(im, cax=cbar_ax)\n",
    "    plt.show()\n",
    "\n",
    "    # plot the histogram \n",
    "    for i in [0,1]:\n",
    "        u, std = np.mean(hist_data[i]), np.std(hist_data[i])\n",
    "        plt.hist(hist_data[i], \n",
    "                density=True,\n",
    "                bins=60, \n",
    "                alpha=0.5, \n",
    "                label=f'{titles[i]}; u={u:.3f}, std={std:.3f}', \n",
    "                color=colors[i],\n",
    "                histtype='step')\n",
    "\n",
    "    plt.title(f'{suptitle}')\n",
    "    plt.xlabel('Gamma0 RTC')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    for i, tif in enumerate([tif_1, tif_2]):\n",
    "        print(tif)\n",
    "        for k in meta[i].keys():\n",
    "            print(f'{k} : {meta[i][k]}')\n",
    "        print('\\n')\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "\n",
    "    \n",
    "def plot_difference_maps(\n",
    "    arr_1, \n",
    "    arr_2, \n",
    "    titles=['arr_1','arr_2','diff (arr_1 - arr_2)'],\n",
    "    scales = [[-40,10],[-40,10],[-1,1]],\n",
    "    ylabels=['decibels (dB)','decibels (dB)','decibels (dB)'],\n",
    "    save_path=''):\n",
    "    \n",
    "    diff = arr_1 - arr_2\n",
    "    arrs = [arr_1, arr_2, diff]\n",
    "    stats_arr = np.array(diff)[np.array((np.isfinite(diff)))]\n",
    "    print('Difference Stats')\n",
    "    print(f'min: {stats_arr.min()}', \n",
    "        f'max: {stats_arr.max()}',\n",
    "        f'mean: {stats_arr.mean()}',\n",
    "        f'median: {np.percentile(stats_arr, 50)}',\n",
    "        f'5th percentile: {np.percentile(stats_arr, 5)}',\n",
    "        f'90th percentile: {np.percentile(stats_arr, 95)}',\n",
    "        )\n",
    "\n",
    "    cmaps = ['binary_r','binary_r','bwr']\n",
    "\n",
    "    f, ax = plt.subplots(nrows=4, ncols=1, figsize=(10,40))\n",
    "    for i,arr in enumerate(arrs):\n",
    "        im = ax[i].imshow(arr[0], \n",
    "                vmin = scales[i][0], \n",
    "                vmax = scales[i][1],\n",
    "                cmap = cmaps[i])\n",
    "        ax[i].set_title(titles[i])\n",
    "        f.colorbar(im, ax=ax[i], label=ylabels[i])\n",
    "        \n",
    "    # plot the histogram\n",
    "    colors = ['red','blue']\n",
    "    for i in [0,1]:\n",
    "        # only get real values \n",
    "        hist_data = np.array(arrs[i])[\n",
    "                (np.isfinite(np.array(arrs[i])))\n",
    "                ]\n",
    "        u, std = np.mean(hist_data), np.std(hist_data)\n",
    "        ax[3].hist(hist_data, \n",
    "                density=True,\n",
    "                bins=60, \n",
    "                alpha=0.5, \n",
    "                label=f'{titles[i]}; u={u:.3f}, std={std:.3f}', \n",
    "                color=colors[i],\n",
    "                histtype='step')\n",
    "        ax[3].set_title('Pixel distribution')\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general structure for scenes in s3\n",
    "# s3_bucket/software/dem/scene/scene_files\n",
    "s3_bucket = 'deant-data-public-dev'\n",
    "s3_bucket_link = 'https://deant-data-public-dev.s3.ap-southeast-2.amazonaws.com/'\n",
    "\n",
    "scenes = [\n",
    "        'S1B_IW_SLC__1SSH_20190223T222639_20190223T222706_015079_01C2E9_1D63',\n",
    "        'S1A_IW_SLC__1SSH_20190605T222724_20190605T222751_027550_031BE1_AD3A',\n",
    "        'S1A_IW_SLC__1SSH_20190926T124734_20190926T124804_029192_0350B9_FA6B',\n",
    "        'S1A_IW_SLC__1SSH_20230127T142750_20230127T142817_046970_05A22F_17F7',\n",
    "        'S1B_IW_SLC__1SSH_20190315T195015_20190315T195045_015369_01CC73_DB8B',\n",
    "        'S1B_IW_SLC__1SSH_20210223T233056_20210223T233124_025740_031194_E7BE',\n",
    "        'S1B_IW_SLC__1SSH_20210228T035005_20210228T035033_025801_03138F_8CB2',\n",
    "]\n",
    "softwares = ['pyrosar','rtc-opera','hyp3-gamma', 'S1_NRB']\n",
    "dems = ['glo_30','REMA_32']\n",
    "\n",
    "# get crededentials for AWS\n",
    "with open('aws_credentials.txt') as f:\n",
    "    ACCESS_ID, ACCESS_KEY = f.readlines()\n",
    "    ACCESS_ID = ACCESS_ID.strip()\n",
    "    ACCESS_KEY = ACCESS_KEY.strip()\n",
    "\n",
    "# setup s3\n",
    "s3 = boto3.client('s3', \n",
    "                        region_name='ap-southeast-2',\n",
    "                        aws_access_key_id=ACCESS_ID,\n",
    "                        aws_secret_access_key= ACCESS_KEY)\n",
    "\n",
    "# make data directory to store local files\n",
    "os.makedirs('data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show example scene files for software"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Products**\n",
    "- RTC products are stored in the s3 bucket specified above\n",
    "- The general pattern for the products is : ```software/dem/crs/scene/files```\n",
    "\n",
    "**Projections**\n",
    "- pyrosar and rtc-opera are projected in 3031 polar steregraphic coordinates \n",
    "- hype-gamma and S1_NRB products are provided in UTM zone projections (output crs cannot be specified)\n",
    "- S1_NRB products are split accross crs zones, with auxillary products produced using the sentinel-2 MRGS tiling grid\n",
    "    - A singe scene ID is therefore split across multiple crs folders\n",
    "    - aux products are written to the final crs folder for each product\n",
    "\n",
    "**Data**\n",
    "- Naming convention for rtc backscatter differs for each product\n",
    "\n",
    "**Metadata**\n",
    "- Metadata products are stored differently between products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = []\n",
    "for software in softwares:\n",
    "    for dem in dems:\n",
    "        params = {\n",
    "            \"Bucket\": f'{s3_bucket}',\n",
    "            \"Prefix\": f'{software}/{dem}'\n",
    "        }\n",
    "        objects = s3.list_objects_v2(**params)\n",
    "        if 'Contents' in objects.keys():\n",
    "            data = objects['Contents']\n",
    "            file_list.extend([x for x in objects['Contents']])\n",
    "\n",
    "# save all of the files in a dataframe for east of searching\n",
    "df_s3 = pd.DataFrame.from_records(file_list)\n",
    "df_s3[['software','dem','crs','scene','file']] = df_s3['Key'].str.split('/', n=4, expand=True)\n",
    "df_s3.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare total timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit to single dem and proj\n",
    "df_timing_files = df_s3[(\n",
    "    (df_s3['file'].str.contains('_timing.json'))\n",
    "    #& (df_s3['dem']==dem)\n",
    "    #& (df_s3['crs']==proj\n",
    "    )]\n",
    "df_timing_files.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_data = []\n",
    "for i in range(0,len(df_timing_files)):\n",
    "    timing_file = df_timing_files.iloc[i].Key\n",
    "    #print(timing_file)\n",
    "    try:\n",
    "        s3.download_file(s3_bucket, timing_file, 'tmp.json')\n",
    "        with open('tmp.json') as json_file:\n",
    "            data = json.load(json_file)\n",
    "            data['software'] = df_timing_files.iloc[i].software\n",
    "            data['scene'] = df_timing_files.iloc[i].scene\n",
    "        timing_data.append(data)\n",
    "        #print(f'downloaded: {timing_file}')\n",
    "    except:\n",
    "        ...\n",
    "        #print(f'no timing file: {timing_file}')\n",
    "\n",
    "os.remove('tmp.json')\n",
    "df_timing = pd.DataFrame.from_records(timing_data, index=['software','scene'])\n",
    "\n",
    "# gamma values are in list for some reason\n",
    "for col in list(df_timing):\n",
    "    df_timing[col] = df_timing[col].apply(lambda x : x[0] if isinstance(x,list) else x)\n",
    "\n",
    "# min timing filter to remove false information\n",
    "min_time = 1000\n",
    "df_timing = df_timing[df_timing['Total']>min_time]\n",
    "\n",
    "# plot mean time by software\n",
    "sw_count = df_timing.groupby('software').size()\n",
    "ax = (df_timing.groupby('software').mean()\n",
    " .drop(columns=['Total'])\n",
    " .plot.bar(stacked=True))\n",
    "ax.set_xlabel('Software')\n",
    "ax.set_ylabel('Time (seconds)')\n",
    "ax.set_title(f'Software Processing Mean Times (DEM upsampling=2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_count.plot(kind='bar', title='product timing file count by software')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relative Comparison of Scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditions for the comparison\n",
    "- we want a single dependant variable to compare the scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_s3.groupby(['scene','software'])['crs'].unique()\n",
    "df_s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the settings for the comparison\n",
    "# compare 1 scene agains a single dependant variable (e.g. dem, software, proj)\n",
    "scene = 'S1A_IW_SLC__1SSH_20230116T100627_20230116T100655_046807_059CB3_FCC7'\n",
    "# scene 1 variables\n",
    "software_1 = 'pyrosar'\n",
    "dem_1 = 'glo_30'\n",
    "crs_1 = 3031\n",
    "label_1 = f'{software_1}-{dem_1}-{crs_1}'\n",
    "# scene 2 variables\n",
    "software_2 = 'hyp3-gamma'\n",
    "dem_2 = 'glo_30'\n",
    "crs_2 = 32758\n",
    "label_2 = f'{software_2}-{dem_2}-{crs_2}'\n",
    "# set the target crs\n",
    "target_crs = 3031\n",
    "\n",
    "print('Relative Comparison')\n",
    "print(f'SCENE 1 - {label_1}')\n",
    "print(f'SCENE 2 - {label_2}')\n",
    "print(f'All pixel based comparisons will be undertaken at target crs : {target_crs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependant_var = 'software'\n",
    "dependant_vals = ['pyrosar','hyp3-gamma']\n",
    "independant_var1 = 'dem'\n",
    "independant_val1 = 'glo_30'\n",
    "\n",
    "print(f'Comparing scenes with varying {dependant_var} : {dependant_vals}')\n",
    "print(f'Keeping {independant_var1} fixed: {independant_val1}')\n",
    "\n",
    "df_comparison = df_s3[(\n",
    "    (df_s3['scene'] == scene)\n",
    "    & (\n",
    "        (((df_s3['software'] == software_1) & (df_s3['dem'] == dem_1) & (df_s3['crs'].isin([crs_1,str(crs_1)])))\n",
    "        |\n",
    "        ((df_s3['software'] == software_2) & (df_s3['dem'] == dem_2) & (df_s3['crs'].isin([crs_2,str(crs_2)])))\n",
    "    ))\n",
    ")\n",
    "]\n",
    "\n",
    "scene_tifs = df_comparison[(\n",
    "      (df_comparison.file.str.contains('rtc|HH')) &\n",
    "      (df_comparison.file.str.endswith('tif'))\n",
    "      )]\n",
    "scene_dems = df_comparison[(df_comparison.file.str.endswith('_dem.tif'))]\n",
    "print(f'{len(scene_tifs)} scene tifs found meeting conditions')\n",
    "print(f'{len(scene_dems)} scene dems found meeting conditions')\n",
    "assert len(scene_tifs)==2, 'just two scenes meeting conditions are required for comparison'\n",
    "assert len(scene_tifs)==2, 'just two dems meeting conditions are required for comparison'\n",
    "\n",
    "# determine which scenes need to be reprojected\n",
    "scene_tifs['reproject'] = scene_tifs['crs'].apply(lambda x : False if str(x) == str(target_crs) else True)\n",
    "scene_tifs[['software','dem','crs','Size','reproject','file']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the tifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download tifs and store locally\n",
    "download = False\n",
    "if download:\n",
    "    for i in range(0,len(scene_tifs)):\n",
    "        key = scene_tifs.iloc[i].Key\n",
    "        filename = scene_tifs.iloc[i].file\n",
    "        print(f'downloading {filename}')\n",
    "        s3.download_file(s3_bucket, key, f'data/tifs/{filename}')\n",
    "scene_tifs['local_file'] = scene_tifs['file'].apply(lambda x : f'data/tifs/{x}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of outputs in native crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the two tiffs side by side with native projections, shapes etc\n",
    "plot_tifs(\n",
    "    scene_tifs.iloc[0].local_file, \n",
    "    scene_tifs.iloc[1].local_file, \n",
    "    titles= [label_1, label_2],\n",
    "    suptitle=f'{scene}',\n",
    "    convert_dB = True,\n",
    "    cmap = 'binary_r',\n",
    "    scale=[-40,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of rasters in target crs\n",
    "- Project rasters to the same resolutions and shapes to enable a direct difference\n",
    "- Note differences may be due to geometric differences and not intensity\n",
    "- Be sure to inspect the pixel shift below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the scene geom in 4326\n",
    "asf.constants.CMR_TIMEOUT = 45\n",
    "asf_result = asf.granule_search([scene], asf.ASFSearchOptions(processingLevel='SLC'))[0]\n",
    "points = (asf_result.__dict__['umm']['SpatialExtent']['HorizontalSpatialDomain']\n",
    "                ['Geometry']['GPolygons'][0]['Boundary']['Points'])\n",
    "points = [(p['Longitude'],p['Latitude']) for p in points]\n",
    "scene_poly = Polygon(points)\n",
    "str(scene_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local files\n",
    "print(scene_tifs.iloc[0].local_file)\n",
    "print(scene_tifs.iloc[1].local_file)\n",
    "# assign crs to missing pyrosar if it does not already have\n",
    "# this is an error with pyrosar not correctly assigning the crs\n",
    "for i in range(len(scene_tifs)):\n",
    "    if scene_tifs.iloc[i].software == 'pyrosar':\n",
    "        print(f'assigning crs to {scene_tifs.iloc[i].local_file}')\n",
    "        assign_crs(scene_tifs.iloc[i].local_file, scene_tifs.iloc[i].crs,)\n",
    "tif_1_f = rioxarray.open_rasterio(scene_tifs.iloc[0].local_file)\n",
    "tif_2_f = rioxarray.open_rasterio(scene_tifs.iloc[1].local_file)\n",
    "# clip by the scene geometry\n",
    "tif_1_clipped = tif_1_f.rio.clip([scene_poly], CRS.from_epsg(4326))\n",
    "tif_2_clipped = tif_2_f.rio.clip([scene_poly], CRS.from_epsg(4326))\n",
    "# clear some mem\n",
    "del tif_1_f, tif_2_f\n",
    "print('Shape of arrays after being clipped by scene bounds')\n",
    "print(tif_1_clipped.shape, tif_2_clipped.shape)\n",
    "print(f'target crs: {target_crs}, crs_1: {scene_tifs.iloc[0].crs}, crs_2: {scene_tifs.iloc[1].crs}')\n",
    "# reproject raster to target crs if not already\n",
    "print('reprojecting arrays if not in target crs')\n",
    "tif_1_reproj = tif_1_clipped.rio.reproject(f\"EPSG:{target_crs}\") if str(scene_tifs.iloc[0].crs) != str(target_crs) else tif_1_clipped\n",
    "tif_2_reproj = tif_2_clipped.rio.reproject(f\"EPSG:{target_crs}\") if str(scene_tifs.iloc[1].crs) != str(target_crs) else tif_2_clipped\n",
    "# tif_1_reproj = tif_1_clipped.copy()\n",
    "# tif_2_reproj = tif_2_clipped.copy()\n",
    "del tif_1_clipped, tif_2_clipped\n",
    "print('Shape of arrays after reprojection to target crs')\n",
    "print(tif_1_reproj.shape, tif_2_reproj.shape)\n",
    "# match the shape and resolution of the two tifs as they may be slighly off\n",
    "# match tif 2 to tif 1 if tif 1 did not require reprojection\n",
    "if str(scene_tifs.iloc[0].crs) == str(target_crs):\n",
    "    print('reprojecting tif 2 to tif 1')\n",
    "    tif_2_matched = tif_2_reproj.rio.reproject_match(tif_1_reproj)\n",
    "    tif_1_matched = tif_1_reproj.copy()\n",
    "else:\n",
    "    print('reprojecting tif 1 to tif 2')\n",
    "    tif_1_matched = tif_1_reproj.rio.reproject_match(tif_2_reproj)\n",
    "    tif_2_matched = tif_2_reproj.copy()\n",
    "del tif_1_reproj, tif_2_reproj\n",
    "print('Shape of arrays after matching tifs')\n",
    "print(tif_1_matched.shape, tif_2_matched.shape)\n",
    "print('converting from linear to db')\n",
    "tif_1_db = 10*np.log10(tif_1_matched)\n",
    "tif_2_db = 10*np.log10(tif_2_matched)\n",
    "del tif_1_matched, tif_2_matched\n",
    "# # calculate the difference between the two images\n",
    "diff = tif_1_db - tif_2_db\n",
    "# relative difference as a % of tif_2\n",
    "# rel_deff = 100*(diff/tif_2_clipped)\n",
    "# save tifs\n",
    "tif_1_db.rio.to_raster(f'data/tifs/{scene}_{label_1}_clipped.tif')\n",
    "tif_2_db.rio.to_raster(f'data/tifs/{scene}_{label_2}_clipped.tif')\n",
    "diff.rio.to_raster(f'data/tifs/{scene}_diff_clipped.tif')\n",
    "scene_tifs['diff_db_path'] = f'data/tifs/{scene}_diff_clipped.tif'\n",
    "scene_tifs['local_matched_db_path'] =  0\n",
    "scene_tifs['local_matched_db_path'].iloc[0] = f'data/tifs/{scene}_{label_1}_clipped.tif'\n",
    "scene_tifs['local_matched_db_path'].iloc[1]= f'data/tifs/{scene}_{label_2}_clipped.tif'\n",
    "scene_tifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample \n",
    "# upscale_factor = 0.1\n",
    "upscale_factor = False\n",
    "if upscale_factor:\n",
    "    new_width = int(tif_1_db.rio.width * upscale_factor)\n",
    "    new_height = int(tif_1_db.rio.height * upscale_factor)\n",
    "\n",
    "    tif_1_db = tif_1_db.rio.reproject(\n",
    "        tif_1_db.rio.crs,\n",
    "        shape=(new_height, new_width),\n",
    "        resampling=Resampling.bilinear,\n",
    "    )\n",
    "\n",
    "    tif_2_db = tif_2_db.rio.reproject(\n",
    "        tif_2_db.rio.crs,\n",
    "        shape=(new_height, new_width),\n",
    "        resampling=Resampling.bilinear,\n",
    "    )\n",
    "\n",
    "    diff = tif_1_db - tif_2_db\n",
    "    print(diff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [[-40,10],[-40,10],[-1,1]]\n",
    "titles = [f'{label_1}',\n",
    "          f'{label_2}',\n",
    "          f'abs difference ([{label_1}] - [{label_2}])']\n",
    "plot_difference_maps(\n",
    "      tif_1_db, \n",
    "      tif_2_db,\n",
    "      titles=titles,\n",
    "      scales=scales,\n",
    "      save_path=f'data/compare-rtc/{scene}_{label_1}_vs_{label_2}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise geometric shift between results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x1,x2,y1,y2 = 8600,9000,6600,7000 # full res\n",
    "#x1,x2,y1,y2 = 3400,4000,9400,10000 # full res\n",
    "x1,x2,y1,y2 = 6500,6900,4600,5000 # full res\n",
    "#x1,x2,y1,y2 = 2000,2500,8600,9100 # full res\n",
    "#x1,x2,y1,y2 = 7000,7500,3800,4300# full res\n",
    "if upscale_factor:\n",
    "    x1,x2,y1,y2 = [int(n*upscale_factor) for n in [x1,x2,y1,y2]] # adjust for scaling\n",
    "tif_1_snip = tif_1_db[0][y1:y2,x1:x2]\n",
    "tif_2_snip = tif_2_db[0][y1:y2,x1:x2]\n",
    "animation = make_gif(\n",
    "    [tif_2_snip, tif_1_snip], \n",
    "    vmin=-40, \n",
    "    vmax=10, \n",
    "    title=f'{dependant_vals[0]}_vs_{dependant_vals[1]}')\n",
    "animation.save(f'data/compare-rtc/{scene}_{label_1}_vs_{label_2}.gif')\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coregtister the Images with Arosics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arosics\n",
    "# img_trg is the one that is shifted\n",
    "# move image 2 to align with image 1\n",
    "scene_tifs['local_coreg_db_path'] = 0\n",
    "scene_tifs['local_coreg_db_path'].iloc[0]= f'data/tifs/{scene}_{label_1}_clipped.tif'\n",
    "scene_tifs['local_coreg_db_path'].iloc[1]= f'data/tifs/{scene}_{label_2}_coreg.tif'\n",
    "\n",
    "coreg = arosics.CoReg.COREG(\n",
    "    im_ref=f'{scene_tifs.iloc[0].local_matched_db_path}', \n",
    "    im_tgt=f'{scene_tifs.iloc[1].local_matched_db_path}', \n",
    "    path_out=f'{scene_tifs[\"local_coreg_db_path\"].iloc[1]}', \n",
    "    fmt_out='GTIFF',\n",
    "    align_grids=True)\n",
    "res = coreg.correct_shifts()\n",
    "\n",
    "# movement statistics \n",
    "offest_stats = {\n",
    "    'x_shift_px': coreg.x_shift_px,\n",
    "    'y_shift_px': coreg.y_shift_px,\n",
    "    'x_shift_map': coreg.x_shift_map,\n",
    "    'y_shift_map': coreg.y_shift_map,\n",
    "    'vec_length_map': coreg.vec_length_map,\n",
    "    'vec_angle_deg': coreg.vec_angle_deg,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Movement from {label_2} to {label_1}')\n",
    "for k in offest_stats.keys():\n",
    "    print(f'{k}: {offest_stats[k]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_1_db = rioxarray.open_rasterio(f'{scene_tifs[\"local_coreg_db_path\"].iloc[0]}')\n",
    "tif_2_db = rioxarray.open_rasterio(f'{scene_tifs[\"local_coreg_db_path\"].iloc[1]}')\n",
    "\n",
    "tif_1_snip = tif_1_db[0][y1:y2,x1:x2]\n",
    "tif_2_snip = tif_2_db[0][y1:y2,x1:x2]\n",
    "animation = make_gif(\n",
    "    [tif_2_snip, \n",
    "    tif_1_snip], \n",
    "    vmin=-40, \n",
    "    vmax=10, \n",
    "    title=f'{dependant_vals[0]}_vs_{dependant_vals[1]}_aligned')\n",
    "animation.save(f'data/compare-rtc/{scene}_{dependant_vals[0]}_vs_{dependant_vals[1]}_aligned.gif')\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [[-40,10],[-40,10],[-1,1]]\n",
    "titles = [f'{label_1}-coreg',f'{label_2}_coreg',\n",
    "          f'abs difference ({label_1}-coreg',f'{label_2}_coreg)']\n",
    "plot_difference_maps(\n",
    "      tif_1_db, \n",
    "      tif_2_db,\n",
    "      titles=titles,\n",
    "      scales=scales,\n",
    "      save_path=f'data/compare-rtc/{scene}_{label_1}_vs_{label_2}_coreg.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the DEMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download tifs and store locally\n",
    "local_dems = []\n",
    "download = False\n",
    "if download:\n",
    "      for i in range(0,len(scene_dems)):\n",
    "            key = scene_dems.iloc[i].Key\n",
    "            filename = scene_dems.iloc[i].file\n",
    "            sw = scene_dems.iloc[i].software\n",
    "            label = f'{scene_dems.software.iloc[i]}-{scene_dems.dem.iloc[i]}-{scene_dems.crs.iloc[i]}'\n",
    "            s3.download_file(s3_bucket, key, f'data/tifs/{label}-{filename}')\n",
    "scene_dems['label'] = scene_dems[['software', 'dem', 'crs']].agg('-'.join, axis=1)\n",
    "scene_dems['local_file'] = f'data/tifs/' + scene_dems['label'] + '-' + scene_dems['file']\n",
    "scene_dems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear mem\n",
    "tif_1_db = tif_2_db = coreg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the dems\n",
    "print(f'{scene_dems[\"local_file\"].iloc[0]}')\n",
    "tif_1_dem = rioxarray.open_rasterio(f'{scene_dems[\"local_file\"].iloc[0]}')\n",
    "print(f'{scene_dems[\"local_file\"].iloc[1]}')\n",
    "tif_2_dem = rioxarray.open_rasterio(f'{scene_dems[\"local_file\"].iloc[1]}')\n",
    "# set the target crs\n",
    "# clip by scene geom\n",
    "print(tif_1_dem.rio.crs, tif_2_dem.rio.crs)\n",
    "print('Shape before scene clip')\n",
    "print(tif_1_dem.shape, tif_2_dem.shape)\n",
    "tif_1_dem = tif_1_dem.rio.clip([scene_poly], CRS.from_epsg(4326))\n",
    "tif_2_dem = tif_2_dem.rio.clip([scene_poly], CRS.from_epsg(4326))\n",
    "print('Shape after scene clip')\n",
    "print(tif_1_dem.shape, tif_2_dem.shape)\n",
    "# reproject raster to target crs if not already\n",
    "print('reprojecting arrays if not in target crs')\n",
    "tif_1_dem_reproj = tif_1_dem.rio.reproject(f\"EPSG:{target_crs}\") if str(scene_dems.iloc[0].crs) != str(target_crs) else tif_1_dem\n",
    "tif_2_dem_reproj = tif_2_dem.rio.reproject(f\"EPSG:{target_crs}\") if str(scene_dems.iloc[1].crs) != str(target_crs) else tif_2_dem\n",
    "# tif_1_reproj = tif_1_dem.copy()\n",
    "# tif_2_reproj = tif_2_dem.copy()\n",
    "del tif_1_dem, tif_2_dem\n",
    "print('Shape of arrays after reprojection to target crs')\n",
    "print(tif_1_dem_reproj.shape, tif_2_dem_reproj.shape)\n",
    "# match the shape and resolution of the two tifs as they may be slighly off\n",
    "# match tif 2 to tif 1 if tif 1 did not require reprojection\n",
    "if str(scene_dems.iloc[0].crs) == str(target_crs):\n",
    "    print('reprojecting tif 2 to tif 1')\n",
    "    tif_2_dem_matched = tif_2_dem_reproj.rio.reproject_match(tif_1_dem_reproj)\n",
    "    tif_1_dem_matched = tif_1_dem_reproj.copy()\n",
    "else:\n",
    "    print('reprojecting tif 1 to tif 2')\n",
    "    tif_1_dem_matched = tif_1_dem_reproj.rio.reproject_match(tif_2_dem_reproj)\n",
    "    tif_2_dem_matched = tif_2_dem_reproj.copy()\n",
    "del tif_1_dem_reproj, tif_2_dem_reproj\n",
    "print('Shape of arrays after matching tifs')\n",
    "print(tif_1_dem_matched.shape, tif_2_dem_matched.shape)\n",
    "# # convert to np arrays\n",
    "# tif_1_dem = np.array(tif_1_dem)\n",
    "# tif_2_dem = np.array(tif_2_dem)\n",
    "# tif_1_dem[(tif_1_dem==-9999)] = np.nan # replace nodata with -9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_1_dem = np.array(tif_1_dem_matched).astype(np.float32)\n",
    "tif_2_dem = np.array(tif_2_dem_matched).astype(np.float32)\n",
    "tif_2_dem[(tif_2_dem==tif_2_dem_matched.rio.nodata)] = np.nan\n",
    "tif_1_dem[(tif_1_dem==tif_1_dem_matched.rio.nodata)] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try and adjust for pixel size (30m/20)\n",
    "x1,x2,y1,y2 = (np.array((x1,x2,y1,y2))*(1/3)).astype(int)\n",
    "print(x1,x2,y1,y2)\n",
    "tif_1_dem_snip = tif_1_dem[0][y1:y2,x1:x2]\n",
    "tif_2_dem_snip = tif_2_dem[0][y1:y2,x1:x2]\n",
    "# replace pyrosar nodata of -9999 with nans\n",
    "animation = make_gif([tif_2_dem_snip, tif_1_dem_snip], vmin=0, vmax=None)\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [[0,3000],[0,3000],[-100,100]]\n",
    "titles = [f'{scene_dems[\"file\"].iloc[0]}',\n",
    "          f'{scene_dems[\"file\"].iloc[1]}',\n",
    "          f'abs difference ({scene_dems[\"file\"].iloc[0]} - {scene_dems[\"file\"].iloc[1]})']\n",
    "ylabels = ['elevation (m)', 'elevation (m)', 'elevation difference (m)']\n",
    "plot_difference_maps(\n",
    "      tif_1_dem, \n",
    "      tif_2_dem,\n",
    "      titles=titles,\n",
    "      scales=scales,\n",
    "      ylabels=ylabels\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_extra_points_along_boundary(bbox, delta=0.1):\n",
    "    \"\"\"\n",
    "    Generate points along the boundary of a bounding box.\n",
    "\n",
    "    Parameters:\n",
    "    - bbox: Tuple of four coordinates (x_min, y_min, x_max, y_max).\n",
    "    - delta: distance between points along the bounding box sides \n",
    "\n",
    "    Returns:\n",
    "    - List of points [(x1, y1), (x2, y2), ...] along the boundary.\n",
    "    \"\"\"\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    # Generate points along the top side\n",
    "    top_side = [(x, y_max) for x in list(np.arange(x_min, x_max, delta)) + [x_max]]    \n",
    "    # Generate points along the right side\n",
    "    right_side = [(x_max, y) for y in list(np.arange(y_max - delta, y_min-delta, -delta)) + [y_min-delta]]\n",
    "    # Generate points along the bottom side\n",
    "    bottom_side = [(x, y_min) for x in list(np.arange(x_max - delta, x_min-delta, -delta)) + [x_min-delta]]\n",
    "    list(np.arange(y_min + delta, y_max, delta)) + [y_max]\n",
    "    # Generate points along the left side\n",
    "    left_side = [(x_min, y) for y in list(np.arange(y_min + delta, y_max, delta)) + [y_max]]\n",
    "    # Combine all sides' points\n",
    "    all_points = top_side + right_side + bottom_side + left_side\n",
    "    return all_points\n",
    "\n",
    "# Example usage:\n",
    "bounding_box = (150, -75, 160, -70)\n",
    "points_along_boundary = generate_points_along_boundary(bounding_box)\n",
    "print(points_along_boundary)\n",
    "Polygon(points_along_boundary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyroSAR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
