{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Sentinel-1 RTC products from different software"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was produced as part of the Digital Earth Antarctica (DEAnt) evaluation of different software options to produce SAR RTC data. Four options have been compares using 'on-the-fly' (otf) pipelines developed for each software. The four softwares options of interest are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import json\n",
    "import rasterio\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.enums import Resampling\n",
    "import rioxarray\n",
    "import asf_search as asf\n",
    "from shapely.geometry import Polygon\n",
    "from celluloid import Camera # getting the camera\n",
    "from IPython.display import HTML\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gif(imgs, vmin, vmax, title=''):\n",
    "    fig, ax = plt.subplots() # make it bigger\n",
    "    camera = Camera(fig)# the camera gets our figure\n",
    "    for i,img in enumerate(imgs):\n",
    "        im = ax.imshow(img,\n",
    "                  vmin=vmin,\n",
    "                  vmax=vmax) # plotting\n",
    "        ax.set_title(f'{title}')\n",
    "        camera.snap()\n",
    "    animation = camera.animate()\n",
    "    return animation\n",
    "\n",
    "def assign_crs(tif_path, crs):\n",
    "    with rasterio.open(tif_path, 'r+') as rds:\n",
    "        rds.crs = CRS.from_epsg(crs)\n",
    "\n",
    "def plot_tifs(\n",
    "    tif_1, \n",
    "    tif_2, \n",
    "    titles= ['arr_1', 'arr_2'],\n",
    "    suptitle='suptitle',\n",
    "    convert_dB = True,\n",
    "    scale=[-40,10],\n",
    "    cmap = 'binary_r',\n",
    "    save_path=''):\n",
    "\n",
    "    # place to store data\n",
    "    hist_data, crss, meta = [],[], []\n",
    "    colors = ['red', 'blue']\n",
    "\n",
    "    # plot the tif\n",
    "    f, ax = plt.subplots(nrows=1, ncols=2, figsize=(18,10))\n",
    "    for i, filename in enumerate([tif_1, tif_2]):\n",
    "        with rasterio.open(f'data/{filename}') as src:\n",
    "                data = src.read(1)\n",
    "                nodata = src.nodata\n",
    "                # covert from linear to db\n",
    "                if convert_dB:\n",
    "                    data = 10*np.log10(data)\n",
    "                # covert no data to nan\n",
    "                data[data==nodata] = np.nan\n",
    "                crss.append(src.meta['crs'])\n",
    "                im = ax[i].imshow(data, cmap=cmap, vmin=scale[0], vmax=scale[1])\n",
    "                ax[i].set_title(f'{titles[i]}')\n",
    "                hist_data.append(data[(np.isfinite(data))])\n",
    "                meta.append(src.meta.copy())\n",
    "\n",
    "    plt.suptitle(f'{suptitle}', y=0.9)\n",
    "    cbar_ax = f.add_axes([0.95, 0.15, 0.04, 0.7])\n",
    "    f.colorbar(im, cax=cbar_ax)\n",
    "    plt.show()\n",
    "\n",
    "    # plot the histogram \n",
    "    for i in [0,1]:\n",
    "        u, std = np.mean(hist_data[i]), np.std(hist_data[i])\n",
    "        plt.hist(hist_data[i], \n",
    "                density=True,\n",
    "                bins=60, \n",
    "                alpha=0.5, \n",
    "                label=f'{titles[i]}; u={u:.3f}, std={std:.3f}', \n",
    "                color=colors[i],\n",
    "                histtype='step')\n",
    "\n",
    "    plt.title(f'{suptitle}')\n",
    "    plt.xlabel('Gamma0 RTC')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    for i, tif in enumerate([tif_1, tif_2]):\n",
    "        print(tif)\n",
    "        for k in meta[i].keys():\n",
    "            print(f'{k} : {meta[i][k]}')\n",
    "        print('\\n')\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "\n",
    "    \n",
    "def plot_difference_maps(\n",
    "    arr_1, \n",
    "    arr_2, \n",
    "    titles=['arr_1','arr_2','diff (arr_1 - arr_2)'],\n",
    "    scales = [[-40,10],[-40,10],[-1,1]],\n",
    "    ylabels=['decibels (dB)','decibels (dB)','decibels (dB)'],\n",
    "    save_path=''):\n",
    "    \n",
    "    diff = arr_1 - arr_2\n",
    "    arrs = [arr_1, arr_2, diff]\n",
    "    stats_arr = np.array(diff)[np.array((np.isfinite(diff)))]\n",
    "    print('Difference Stats')\n",
    "    print(f'min: {stats_arr.min()}', \n",
    "        f'max: {stats_arr.max()}',\n",
    "        f'mean: {stats_arr.mean()}',\n",
    "        f'median: {np.percentile(stats_arr, 50)}',\n",
    "        f'5th percentile: {np.percentile(stats_arr, 5)}',\n",
    "        f'90th percentile: {np.percentile(stats_arr, 95)}',\n",
    "        )\n",
    "\n",
    "    cmaps = ['binary_r','binary_r','bwr']\n",
    "\n",
    "    f, ax = plt.subplots(nrows=4, ncols=1, figsize=(10,40))\n",
    "    for i,arr in enumerate(arrs):\n",
    "        im = ax[i].imshow(arr[0], \n",
    "                vmin = scales[i][0], \n",
    "                vmax = scales[i][1],\n",
    "                cmap = cmaps[i])\n",
    "        ax[i].set_title(titles[i])\n",
    "        f.colorbar(im, ax=ax[i], label=ylabels[i])\n",
    "        \n",
    "    # plot the histogram\n",
    "    colors = ['red','blue']\n",
    "    for i in [0,1]:\n",
    "        # only get real values \n",
    "        hist_data = np.array(arrs[i])[\n",
    "                (np.isfinite(np.array(arrs[i])))\n",
    "                ]\n",
    "        u, std = np.mean(hist_data), np.std(hist_data)\n",
    "        ax[3].hist(hist_data, \n",
    "                density=True,\n",
    "                bins=60, \n",
    "                alpha=0.5, \n",
    "                label=f'{titles[i]}; u={u:.3f}, std={std:.3f}', \n",
    "                color=colors[i],\n",
    "                histtype='step')\n",
    "        ax[3].set_title('Pixel distribution')\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general structure for scenes in s3\n",
    "# s3_bucket/software/dem/scene/scene_files\n",
    "s3_bucket = 'deant-data-public-dev'\n",
    "s3_bucket_link = 'https://deant-data-public-dev.s3.ap-southeast-2.amazonaws.com/'\n",
    "\n",
    "scenes = [\n",
    "        'S1B_IW_SLC__1SSH_20190223T222639_20190223T222706_015079_01C2E9_1D63',\n",
    "        'S1A_IW_SLC__1SSH_20190605T222724_20190605T222751_027550_031BE1_AD3A',\n",
    "        'S1A_IW_SLC__1SSH_20190926T124734_20190926T124804_029192_0350B9_FA6B',\n",
    "        'S1A_IW_SLC__1SSH_20230127T142750_20230127T142817_046970_05A22F_17F7',\n",
    "        'S1B_IW_SLC__1SSH_20190315T195015_20190315T195045_015369_01CC73_DB8B',\n",
    "        'S1B_IW_SLC__1SSH_20210223T233056_20210223T233124_025740_031194_E7BE',\n",
    "        'S1B_IW_SLC__1SSH_20210228T035005_20210228T035033_025801_03138F_8CB2',\n",
    "]\n",
    "softwares = ['pyrosar','rtc-opera','hyp3-gamma']\n",
    "dems = ['glo_30','REMA_32']\n",
    "\n",
    "# get crededentials for AWS\n",
    "with open('aws_credentials.txt') as f:\n",
    "    ACCESS_ID, ACCESS_KEY = f.readlines()\n",
    "    ACCESS_ID = ACCESS_ID.strip()\n",
    "    ACCESS_KEY = ACCESS_KEY.strip()\n",
    "\n",
    "# setup s3\n",
    "s3 = boto3.client('s3', \n",
    "                        region_name='ap-southeast-2',\n",
    "                        aws_access_key_id=ACCESS_ID,\n",
    "                        aws_secret_access_key= ACCESS_KEY)\n",
    "\n",
    "# make data directory to store local files\n",
    "os.makedirs('data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show example scene files for software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = []\n",
    "for software in softwares:\n",
    "    for dem in dems:\n",
    "        params = {\n",
    "            \"Bucket\": f'{s3_bucket}',\n",
    "            \"Prefix\": f'{software}/{dem}'\n",
    "        }\n",
    "        objects = s3.list_objects_v2(**params)\n",
    "        if 'Contents' in objects.keys():\n",
    "            data = objects['Contents']\n",
    "            file_list.extend([x for x in objects['Contents']])\n",
    "\n",
    "# save all of the files in a dataframe for east of searching\n",
    "df_s3 = pd.DataFrame.from_records(file_list)\n",
    "df_s3[['software','dem','crs','scene','file']] = df_s3['Key'].str.split('/', n=4, expand=True)\n",
    "df_s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare total timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit to single dem and proj\n",
    "df_timing_files = df_s3[(\n",
    "    (df_s3['file'].str.contains('_timing.json'))\n",
    "    #& (df_s3['dem']==dem)\n",
    "    #& (df_s3['crs']==proj\n",
    "    )]\n",
    "df_timing_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_data = []\n",
    "for i in range(0,len(df_timing_files)):\n",
    "    timing_file = df_timing_files.iloc[i].Key\n",
    "    print(timing_file)\n",
    "    try:\n",
    "        s3.download_file(s3_bucket, timing_file, 'tmp.json')\n",
    "        with open('tmp.json') as json_file:\n",
    "            data = json.load(json_file)\n",
    "            data['software'] = df_timing_files.iloc[i].software\n",
    "            data['scene'] = df_timing_files.iloc[i].scene\n",
    "        timing_data.append(data)\n",
    "        print(f'downloaded: {timing_file}')\n",
    "    except:\n",
    "        print(f'no timing file: {timing_file}')\n",
    "\n",
    "os.remove('tmp.json')\n",
    "df_timing = pd.DataFrame.from_records(timing_data, index=['software','scene'])\n",
    "\n",
    "# min timing filter to remove false info\n",
    "min_time = 500\n",
    "df_timing = df_timing[df_timing['Total']>min_time]\n",
    "\n",
    "# plot mean time by software\n",
    "sw_count = df_timing.groupby('software').size()\n",
    "ax = (df_timing.groupby('software').mean()\n",
    " .drop(columns=['Total'])\n",
    " .plot.bar(stacked=True))\n",
    "ax.set_xlabel('Software')\n",
    "ax.set_ylabel('Time (seconds)')\n",
    "ax.set_title(f'Software Processing Mean Times (DEM upsampling=2)')\n",
    "print(sw_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare RTC Process Timing\n",
    "- Investigate the logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPERA_RTC_times = {}\n",
    "# read opera logs\n",
    "opera_logs = df_s3[(df_s3['Key'].str.contains('logs')) & (df_s3['software']=='rtc-opera')]\n",
    "logs = s3.get_object(Bucket=s3_bucket, Key=opera_logs['Key'].values[0])\n",
    "logs_content = logs['Body'].read()\n",
    "log_lines = logs_content.decode(\"utf-8\").splitlines()\n",
    "# find the lines with timing info\n",
    "time_lines = [x for x in log_lines if (('time' in x) or ('timing' in x))]\n",
    "GEO_AP = [x for x in time_lines if ('GEO-AP' in x)] # burst AP geometric correction \n",
    "RTC_AP = [x for x in time_lines if ('RTC-AP' in x)] # burst AP radiometric correction\n",
    "CHILD = [x for x in time_lines if ('Child' in x)] # total time for geom/radio correction\n",
    "# multi process is run, meaning we cannot use the sum for total processing time\n",
    "# we therefor take the ratio of total geo/radio process and allocate time\n",
    "GEO_AP_t = sum([float(x.split(': ')[-1]) for x in GEO_AP])\n",
    "RTC_AP_t = sum([float(x.split(': ')[-1]) for x in RTC_AP])\n",
    "RTC_CHILD_t = sum([float(x.split(': ')[-1].split(' ')[0]) for x in CHILD])\n",
    "Total_t = float(time_lines[-1].split(': ')[-1])\n",
    "# add times to doct\n",
    "OPERA_RTC_times['Terration Correction (geometric)'] = (GEO_AP_t/(GEO_AP_t+RTC_AP_t))*RTC_CHILD_t\n",
    "OPERA_RTC_times['Terrain Flattening (radiometric)'] = (RTC_AP_t/(GEO_AP_t+RTC_AP_t))*RTC_CHILD_t\n",
    "OPERA_RTC_times['Mosaicing and formatting'] = Total_t - RTC_CHILD_t\n",
    "OPERA_RTC_times['Total'] = Total_t\n",
    "OPERA_RTC_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyrosar_RTC_times = {}\n",
    "# # read pyrosar logs\n",
    "# pyrosar_logs = df_s3[(df_s3['Key'].str.contains('logs')) & (df_s3['software']=='pyrosar')]\n",
    "# logs = s3.get_object(Bucket=s3_bucket, Key=pyrosar_logs['Key'].values[0])\n",
    "# logs_content = logs['Body'].read()\n",
    "# log_lines = logs_content.decode(\"utf-8\").splitlines()\n",
    "# # # find the lines with timing info\n",
    "# RTC_start = log_lines.index([x for x in log_lines if 'PROCESS 2' in x][0])\n",
    "# RTC_END = log_lines.index([x for x in log_lines if 'RTC Backscatter successfully made' in x][0]) \n",
    "# #log_lines[RTC_start:RTC_END]\n",
    "# # pyrosar_RTC_times['Terration Correction (geometric)'] = (GEO_AP_t/(GEO_AP_t+RTC_AP_t))*RTC_CHILD_t\n",
    "# # pyrosar_RTC_times['Terrain Flattening (radiometric)'] = (RTC_AP_t/(GEO_AP_t+RTC_AP_t))*RTC_CHILD_t\n",
    "# # pyrosar_RTC_times['Mosaicing and formatting'] = Total_t - RTC_CHILD_t\n",
    "# # pyrosar_RTC_times['Total'] = Total_t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Scenes\n",
    "**Differences**\n",
    "- Subtle differences may be caused by apply_bistatic_delay_correction and apply_static_tropospheric_delay_correction for OPERA products\n",
    "- DEM oversampling (2 is default for pyrosar, I think 1 for opera)\n",
    "- Treatment of burst overlaps:\n",
    "    - By default OPERA will select the middle of the burst overlaps \n",
    "    - SNAP selectes one (perhaps the first?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditions for the comparison\n",
    "- we want a single dependant variable to compare the scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the settings for the comparison\n",
    "# compare 1 scene agains a single dependant variable (e.g. dem, software, proj)\n",
    "scene = 'S1B_IW_SLC__1SSH_20190223T222639_20190223T222706_015079_01C2E9_1D63'\n",
    "dependant_var = 'software'\n",
    "dependant_vals = ['rtc-opera','hyp3-gamma']\n",
    "independant_var1 = 'dem'\n",
    "independant_val1 = 'glo_30'\n",
    "independant_var2 = 'crs'\n",
    "independant_val2 = '32743'\n",
    "\n",
    "print(f'Comparing scenes with varying {dependant_var} : {dependant_vals}')\n",
    "print(f'Keeping {independant_var1} fixed: {independant_val1}')\n",
    "print(f'Keeping {independant_var2} fixed: {independant_val2}')\n",
    "\n",
    "df_comparison = df_s3[(\n",
    "    (df_s3[dependant_var].isin(dependant_vals))\n",
    "    & (df_s3[independant_var1] == independant_val1)\n",
    "    & (df_s3[independant_var2] == independant_val2)\n",
    "    & (df_s3['scene'] == scene)\n",
    ")]\n",
    "\n",
    "scene_tifs = df_comparison[(\n",
    "      (df_comparison.file.str.contains('rtc|HH')) &\n",
    "      (df_comparison.file.str.endswith('tif'))\n",
    "      )]\n",
    "scene_dems = df_comparison[(df_comparison.file.str.endswith('_dem.tif'))]\n",
    "print(f'{len(scene_tifs)} scene tifs found meeting conditions')\n",
    "print(f'{len(scene_dems)} scene dems found meeting conditions')\n",
    "assert len(scene_tifs)==2, 'two scenes meeting conditions are required'\n",
    "assert len(scene_tifs)==2, 'two dems meeting conditions are required'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the tifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download tifs and store locally\n",
    "download = True\n",
    "if download:\n",
    "    for i in range(0,len(scene_tifs)):\n",
    "        key = scene_tifs.iloc[i].Key\n",
    "        filename = scene_tifs.iloc[i].file\n",
    "        print(f'downloading {filename}')\n",
    "        s3.download_file(s3_bucket, key, f'data/{filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of raw outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the two tiffs side by side with native projections, shapes etc\n",
    "tif_1_data = scene_tifs[scene_tifs[dependant_var]==dependant_vals[0]].iloc[0]\n",
    "tif_2_data = scene_tifs[scene_tifs[dependant_var]==dependant_vals[1]].iloc[0]\n",
    "\n",
    "plot_tifs(\n",
    "    tif_1_data.file, \n",
    "    tif_2_data.file, \n",
    "    titles= dependant_vals,\n",
    "    suptitle=f'{scene}',\n",
    "    convert_dB = True,\n",
    "    cmap = 'binary_r',\n",
    "    scale=[-40,10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raster Difference Maps\n",
    "- Project rasters to the same resolutions and shapes to enable a direct difference\n",
    "- Note differences may be due to geometric differences and not intensity\n",
    "- Be sure to inspect the pixel shift below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the scene geom in 4326\n",
    "asf.constants.CMR_TIMEOUT = 45\n",
    "asf_result = asf.granule_search([scene], asf.ASFSearchOptions(processingLevel='SLC'))[0]\n",
    "points = (asf_result.__dict__['umm']['SpatialExtent']['HorizontalSpatialDomain']\n",
    "                ['Geometry']['GPolygons'][0]['Boundary']['Points'])\n",
    "points = [(p['Longitude'],p['Latitude']) for p in points]\n",
    "scene_poly = Polygon(points)\n",
    "str(scene_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local files\n",
    "local_tif_1_path = f'data/{tif_1_data.file}'\n",
    "local_tif_2_path = f'data/{tif_2_data.file}'\n",
    "#assign_crs(local_tif_1_path, 3031) # assign missing crs...\n",
    "print(local_tif_1_path)\n",
    "print(local_tif_2_path)\n",
    "tif_1_f = rioxarray.open_rasterio(local_tif_1_path)\n",
    "tif_2_f = rioxarray.open_rasterio(local_tif_2_path)\n",
    "# clip by the scene geometry\n",
    "tif_1_clipped = tif_1_f.rio.clip([scene_poly], CRS.from_epsg(4326))\n",
    "tif_2_clipped = tif_2_f.rio.clip([scene_poly], CRS.from_epsg(4326))\n",
    "del tif_1_f\n",
    "del tif_2_f\n",
    "print(tif_1_clipped.shape, tif_2_clipped.shape)\n",
    "# match the projection/transform/shape\n",
    "tif_1_matched = tif_1_clipped.rio.reproject_match(tif_2_clipped)\n",
    "print(tif_1_matched.shape)\n",
    "# convert to db\n",
    "tif_1_db = 10*np.log10(tif_1_matched)\n",
    "tif_2_db = 10*np.log10(tif_2_clipped)\n",
    "# calculate the difference between the two images\n",
    "diff = tif_1_db - tif_2_db\n",
    "# relative difference as a % of tif_2\n",
    "rel_deff = 100*(diff/tif_2_clipped)\n",
    "# save tifs\n",
    "tif_1_db.rio.to_raster(f'data/{scene}_{dependant_vals[0]}_clipped.tif')\n",
    "tif_2_db.rio.to_raster(f'data/{scene}_{dependant_vals[1]}_clipped.tif')\n",
    "diff.rio.to_raster(f'data/{scene}_diff_clipped.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample \n",
    "# upscale_factor = 0.1\n",
    "upscale_factor = False\n",
    "if upscale_factor:\n",
    "    new_width = int(tif_1_db.rio.width * upscale_factor)\n",
    "    new_height = int(tif_1_db.rio.height * upscale_factor)\n",
    "\n",
    "    tif_1_db = tif_1_db.rio.reproject(\n",
    "        tif_1_db.rio.crs,\n",
    "        shape=(new_height, new_width),\n",
    "        resampling=Resampling.bilinear,\n",
    "    )\n",
    "\n",
    "    tif_2_db = tif_2_db.rio.reproject(\n",
    "        tif_2_db.rio.crs,\n",
    "        shape=(new_height, new_width),\n",
    "        resampling=Resampling.bilinear,\n",
    "    )\n",
    "\n",
    "    diff = tif_1_db - tif_2_db\n",
    "    print(diff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [[-40,10],[-40,10],[-1,1]]\n",
    "titles = [f'{dependant_vals[0]}',\n",
    "          f'{dependant_vals[1]}',\n",
    "          f'abs difference ({dependant_vals[0]} - {dependant_vals[1]}-rtc)']\n",
    "plot_difference_maps(\n",
    "      tif_1_db, \n",
    "      tif_2_db,\n",
    "      titles=titles,\n",
    "      scales=scales,\n",
    "      save_path=f'data/{scene}_{dependant_vals[0]}_vs_{dependant_vals[1]}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See pixel shift in small area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x1,x2,y1,y2 = 8600,9000,6600,7000 # full res\n",
    "#x1,x2,y1,y2 = 3400,4000,9400,10000 # full res\n",
    "#x1,x2,y1,y2 = 6500,6900,4600,5000 # full res\n",
    "x1,x2,y1,y2 = 2000,2500,8600,9100 # full res\n",
    "x1,x2,y1,y2 = 7000,7500,3800,4300# full res\n",
    "if upscale_factor:\n",
    "    x1,x2,y1,y2 = [int(n*upscale_factor) for n in [x1,x2,y1,y2]] # adjust for scaling\n",
    "tif_1_snip = tif_1_db[0][y1:y2,x1:x2]\n",
    "tif_2_snip = tif_2_db[0][y1:y2,x1:x2]\n",
    "animation = make_gif(\n",
    "    [tif_2_snip, tif_1_snip], \n",
    "    vmin=-40, \n",
    "    vmax=10, \n",
    "    title=f'{dependant_vals[0]}_vs_{dependant_vals[1]}')\n",
    "animation.save(f'data/{scene}_{dependant_vals[0]}_vs_{dependant_vals[1]}.gif')\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corestister the Images with Arosics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arosics\n",
    "# img_trg is the one that is shifted\n",
    "coreg = arosics.CoReg.COREG(\n",
    "    im_ref=f'data/{scene}_{dependant_vals[1]}_clipped.tif', \n",
    "    im_tgt=f'data/{scene}_{dependant_vals[0]}_clipped.tif', \n",
    "    path_out=f'data/{scene}_{dependant_vals[0]}_clipped_aligned.tif', \n",
    "    fmt_out='GTIFF',\n",
    "    align_grids=True)\n",
    "res = coreg.correct_shifts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_1_db = rioxarray.open_rasterio(f'data/{scene}_{dependant_vals[0]}_clipped_aligned.tif')\n",
    "tif_2_db = rioxarray.open_rasterio(f'data/{scene}_{dependant_vals[1]}_clipped.tif')\n",
    "\n",
    "tif_1_snip = tif_1_db[0][y1:y2,x1:x2]\n",
    "tif_2_snip = tif_2_db[0][y1:y2,x1:x2]\n",
    "animation = make_gif(\n",
    "    [tif_2_snip, \n",
    "    tif_1_snip], \n",
    "    vmin=-40, \n",
    "    vmax=10, \n",
    "    title=f'{dependant_vals[0]}_vs_{dependant_vals[1]}_aligned')\n",
    "animation.save(f'data/{scene}_{dependant_vals[0]}_vs_{dependant_vals[1]}_aligned.gif')\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [[-40,10],[-40,10],[-1,1]]\n",
    "titles = [f'{dependant_vals[0]}',\n",
    "          f'{dependant_vals[1]}',\n",
    "          f'abs difference ({dependant_vals[0]} - {dependant_vals[1]})']\n",
    "plot_difference_maps(\n",
    "      tif_1_db, \n",
    "      tif_2_db,\n",
    "      titles=titles,\n",
    "      scales=scales,\n",
    "      save_path=f'data/{scene}_{dependant_vals[0]}_vs_{dependant_vals[1]}_aligned.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the DEMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download tifs and store locally\n",
    "local_dems = []\n",
    "for i in range(0,len(scene_dems)):\n",
    "      key = scene_dems.iloc[i].Key\n",
    "      filename = scene_dems.iloc[i].file\n",
    "      sw = scene_dems.iloc[i].software\n",
    "      if not os.path.exists(f'data/{sw}_{filename}'):\n",
    "            print(f'downloading {sw}_{filename}')\n",
    "            s3.download_file(s3_bucket, key, f'data/{sw}_{filename}')\n",
    "      local_dems.append(f'data/{sw}_{filename}')\n",
    "local_dems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear mem\n",
    "tif_1_db = tif_2_db = coreg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the dems\n",
    "tif_1_dem = rioxarray.open_rasterio(f'data/tif_1_{scene}_dem.tif')\n",
    "tif_2_dem = rioxarray.open_rasterio(f'data/rtc-tif_2_{scene}_dem.tif')\n",
    "# clip by scene geom\n",
    "tif_1_dem = tif_1_dem.rio.clip([scene_poly], CRS.from_epsg(4326))\n",
    "tif_2_dem = tif_2_dem.rio.clip([scene_poly], CRS.from_epsg(4326))\n",
    "print(tif_1_dem.shape, tif_2_dem.shape)\n",
    "# match the projection/transform/shape of the dems\n",
    "tif_1_dem = tif_1_dem.rio.reproject_match(tif_2_dem)\n",
    "print(tif_1_dem.shape, tif_2_dem.shape)\n",
    "\n",
    "# convert to np arrays\n",
    "tif_1_dem = np.array(tif_1_dem)\n",
    "tif_2_dem = np.array(tif_2_dem)\n",
    "tif_1_dem[(tif_1_dem==-9999)] = np.nan # replace nodata with -9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try and adjust for pixel size (30m/20)\n",
    "x1,x2,y1,y2 = (np.array((x1,x2,y1,y2))*(2/3)).astype(int)\n",
    "pyrosar_snip = pyrosar_dem[0][y1:y2,x1:x2]\n",
    "opera_snip = opera_dem[0][y1:y2,x1:x2]\n",
    "# replace pyrosar nodata of -9999 with nans\n",
    "animation = make_gif([opera_snip, pyrosar_snip], vmin=None, vmax=None)\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [[None,None],[None,None],[None,None]]\n",
    "titles = ['pyrosar dem (glo-30)',\n",
    "          'opera-rtc dem (glo-30)',\n",
    "          'abs difference (pyrosar - opera-rtc)']\n",
    "ylabels = ['elevation (m)', 'elevation (m)', 'difference (m)']\n",
    "plot_difference_maps(\n",
    "      pyrosar_dem, \n",
    "      opera_dem,\n",
    "      titles=titles,\n",
    "      scales=scales,\n",
    "      ylabels=ylabels\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_extra_points_along_boundary(bbox, delta=0.1):\n",
    "    \"\"\"\n",
    "    Generate points along the boundary of a bounding box.\n",
    "\n",
    "    Parameters:\n",
    "    - bbox: Tuple of four coordinates (x_min, y_min, x_max, y_max).\n",
    "    - delta: distance between points along the bounding box sides \n",
    "\n",
    "    Returns:\n",
    "    - List of points [(x1, y1), (x2, y2), ...] along the boundary.\n",
    "    \"\"\"\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    # Generate points along the top side\n",
    "    top_side = [(x, y_max) for x in list(np.arange(x_min, x_max, delta)) + [x_max]]    \n",
    "    # Generate points along the right side\n",
    "    right_side = [(x_max, y) for y in list(np.arange(y_max - delta, y_min-delta, -delta)) + [y_min-delta]]\n",
    "    # Generate points along the bottom side\n",
    "    bottom_side = [(x, y_min) for x in list(np.arange(x_max - delta, x_min-delta, -delta)) + [x_min-delta]]\n",
    "    list(np.arange(y_min + delta, y_max, delta)) + [y_max]\n",
    "    # Generate points along the left side\n",
    "    left_side = [(x_min, y) for y in list(np.arange(y_min + delta, y_max, delta)) + [y_max]]\n",
    "    # Combine all sides' points\n",
    "    all_points = top_side + right_side + bottom_side + left_side\n",
    "    return all_points\n",
    "\n",
    "# Example usage:\n",
    "bounding_box = (150, -75, 160, -70)\n",
    "points_along_boundary = generate_points_along_boundary(bounding_box)\n",
    "print(points_along_boundary)\n",
    "Polygon(points_along_boundary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyroSAR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
