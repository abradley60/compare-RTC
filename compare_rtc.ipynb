{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Sentinel-1 RTC products from different software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import json\n",
    "import rasterio\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.enums import Resampling\n",
    "import rioxarray\n",
    "import asf_search as asf\n",
    "from shapely.geometry import Polygon\n",
    "from celluloid import Camera # getting the camera\n",
    "from IPython.display import HTML\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gif(imgs, vmin, vmax):\n",
    "    fig, ax = plt.subplots() # make it bigger\n",
    "    camera = Camera(fig)# the camera gets our figure\n",
    "    for i,img in enumerate(imgs):\n",
    "        im = ax.imshow(img,\n",
    "                  vmin=vmin,\n",
    "                  vmax=vmax) # plotting\n",
    "        camera.snap()\n",
    "    animation = camera.animate()\n",
    "    return animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general structure for scenes in s3\n",
    "# s3_bucket/software/dem/scene/scene_files\n",
    "s3_bucket = 'deant-data-public-dev'\n",
    "s3_bucket_link = 'https://deant-data-public-dev.s3.ap-southeast-2.amazonaws.com/'\n",
    "softwares = ['pyrosar','rtc-opera']\n",
    "scenes = [\n",
    "        'S1B_IW_SLC__1SSH_20190223T222639_20190223T222706_015079_01C2E9_1D63',\n",
    "        'S1A_IW_SLC__1SSH_20190605T222724_20190605T222751_027550_031BE1_AD3A',\n",
    "        'S1A_IW_SLC__1SSH_20190926T124734_20190926T124804_029192_0350B9_FA6B',\n",
    "        'S1A_IW_SLC__1SSH_20230127T142750_20230127T142817_046970_05A22F_17F7',\n",
    "        'S1B_IW_SLC__1SSH_20190315T195015_20190315T195045_015369_01CC73_DB8B',\n",
    "        'S1B_IW_SLC__1SSH_20210223T233056_20210223T233124_025740_031194_E7BE',\n",
    "        'S1B_IW_SLC__1SSH_20210228T035005_20210228T035033_025801_03138F_8CB2',\n",
    "]\n",
    "dem = 'glo_30'\n",
    "proj = '3031'\n",
    "\n",
    "# get crededentials for AWS\n",
    "with open('aws_credentials.txt') as f:\n",
    "    ACCESS_ID, ACCESS_KEY = f.readlines()\n",
    "    ACCESS_ID = ACCESS_ID.strip()\n",
    "    ACCESS_KEY = ACCESS_KEY.strip()\n",
    "\n",
    "# setup s3\n",
    "s3 = boto3.client('s3', \n",
    "                        region_name='ap-southeast-2',\n",
    "                        aws_access_key_id=ACCESS_ID,\n",
    "                        aws_secret_access_key= ACCESS_KEY)\n",
    "\n",
    "# make data directory to store local files\n",
    "os.makedirs('data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show example scene files for software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = []\n",
    "for software in softwares:\n",
    "    for i,scene in enumerate(scenes):\n",
    "        params = {\n",
    "            \"Bucket\": f'{s3_bucket}',\n",
    "            \"Prefix\": f'{software}/{dem}/{proj}/{scene}'\n",
    "        }\n",
    "        objects = s3.list_objects_v2(**params)\n",
    "        if 'Contents' in objects.keys():\n",
    "            if i == 0:\n",
    "                print(f'software : {software}')\n",
    "                for x in objects['Contents']:\n",
    "                    print(x)\n",
    "            data = objects['Contents']\n",
    "            file_list.extend([x for x in objects['Contents']])\n",
    "\n",
    "# save all of the files in a dataframe for east of searching\n",
    "df_s3 = pd.DataFrame.from_records(file_list)\n",
    "df_s3[['software','dem','crs','scene','file']] = df_s3['Key'].str.split('/', n=4, expand=True)\n",
    "#df_s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare total timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_data = []\n",
    "for software in softwares:\n",
    "    for scene in scenes:\n",
    "        timing_file = f'{software}/{dem}/{proj}/{scene}/{scene}_timing.json'\n",
    "        try:\n",
    "            s3.download_file(s3_bucket, timing_file, 'tmp.json')\n",
    "            with open('tmp.json') as json_file:\n",
    "                data = json.load(json_file)\n",
    "                data['software'] = software\n",
    "                data['scene'] = scene\n",
    "            timing_data.append(data)\n",
    "            print(f'downloaded: {timing_file}')\n",
    "        except:\n",
    "            print(f'no timing file: {timing_file}')\n",
    "\n",
    "os.remove('tmp.json')\n",
    "df_timing = pd.DataFrame.from_records(timing_data, index=['software','scene'])\n",
    "\n",
    "# plot mean time by software\n",
    "sw_count = df_timing.groupby('software').size()\n",
    "ax = (df_timing.groupby('software').mean()\n",
    " .drop(columns=['Total'])\n",
    " .plot.bar(stacked=True))\n",
    "ax.set_xlabel('Software')\n",
    "ax.set_ylabel('Time (seconds)')\n",
    "ax.set_title(f'Software Processing Times (DEM upsampling=2)')\n",
    "print(sw_count)\n",
    "df_timing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare RTC Process Timing\n",
    "- Investigate the logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPERA_RTC_times = {}\n",
    "# read opera logs\n",
    "opera_logs = df_s3[(df_s3['Key'].str.contains('logs')) & (df_s3['software']=='rtc-opera')]\n",
    "logs = s3.get_object(Bucket=s3_bucket, Key=opera_logs['Key'].values[1])\n",
    "logs_content = logs['Body'].read()\n",
    "log_lines = logs_content.decode(\"utf-8\").splitlines()\n",
    "# find the lines with timing info\n",
    "time_lines = [x for x in log_lines if (('time' in x) or ('timing' in x))]\n",
    "GEO_AP = [x for x in time_lines if ('GEO-AP' in x)] # burst AP geometric correction \n",
    "RTC_AP = [x for x in time_lines if ('RTC-AP' in x)] # burst AP radiometric correction\n",
    "CHILD = [x for x in time_lines if ('Child' in x)] # total time for geom/radio correction\n",
    "# multi process is run, meaning we cannot use the sum for total processing time\n",
    "# we therefor take the ratio of total geo/radio process and allocate time\n",
    "GEO_AP_t = sum([float(x.split(': ')[-1]) for x in GEO_AP])\n",
    "RTC_AP_t = sum([float(x.split(': ')[-1]) for x in RTC_AP])\n",
    "RTC_CHILD_t = sum([float(x.split(': ')[-1].split(' ')[0]) for x in CHILD])\n",
    "Total_t = float(time_lines[-1].split(': ')[-1])\n",
    "# add times to doct\n",
    "OPERA_RTC_times['Terration Correction (geometric)'] = (GEO_AP_t/(GEO_AP_t+RTC_AP_t))*RTC_CHILD_t\n",
    "OPERA_RTC_times['Terrain Flattening (radiometric)'] = (RTC_AP_t/(GEO_AP_t+RTC_AP_t))*RTC_CHILD_t\n",
    "OPERA_RTC_times['Mosaicing and formatting'] = Total_t - RTC_CHILD_t\n",
    "OPERA_RTC_times['Total'] = Total_t\n",
    "OPERA_RTC_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyrosar_RTC_times = {}\n",
    "# read pyrosar logs\n",
    "pyrosar_logs = df_s3[(df_s3['Key'].str.contains('logs')) & (df_s3['software']=='pyrosar')]\n",
    "logs = s3.get_object(Bucket=s3_bucket, Key=pyrosar_logs['Key'].values[0])\n",
    "logs_content = logs['Body'].read()\n",
    "log_lines = logs_content.decode(\"utf-8\").splitlines()\n",
    "# # find the lines with timing info\n",
    "RTC_start = log_lines.index([x for x in log_lines if 'PROCESS 2' in x][0])\n",
    "RTC_END = log_lines.index([x for x in log_lines if 'RTC Backscatter successfully made' in x][0]) \n",
    "#log_lines[RTC_start:RTC_END]\n",
    "# pyrosar_RTC_times['Terration Correction (geometric)'] = (GEO_AP_t/(GEO_AP_t+RTC_AP_t))*RTC_CHILD_t\n",
    "# pyrosar_RTC_times['Terrain Flattening (radiometric)'] = (RTC_AP_t/(GEO_AP_t+RTC_AP_t))*RTC_CHILD_t\n",
    "# pyrosar_RTC_times['Mosaicing and formatting'] = Total_t - RTC_CHILD_t\n",
    "# pyrosar_RTC_times['Total'] = Total_t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Values\n",
    "**Differences**\n",
    "- Subtle differences may be caused by apply_bistatic_delay_correction and apply_static_tropospheric_delay_correction for OPERA products\n",
    "- DEM oversampling (2 is default for pyrosar, I think 1 for opera)\n",
    "- Treatment of burst overlaps:\n",
    "    - By default OPERA will select the middle of the burst overlaps \n",
    "    - SNAP selectes one (perhaps the first?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the scene\n",
    "scene = scenes[0]\n",
    "scene_tifs = df_s3[(df_s3['scene'] == scene) & \n",
    "      (df_s3.file.str.contains('RTC|rtc')) &\n",
    "      (df_s3.file.str.contains('tif'))\n",
    "      ]\n",
    "scene_tifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download tifs and store locally\n",
    "for i in range(0,len(scene_tifs)):\n",
    "      key = scene_tifs.iloc[i].Key\n",
    "      filename = scene_tifs.iloc[i].file\n",
    "      if not os.path.exists(f'data/{filename}'):\n",
    "            print(f'downloading {filename}')\n",
    "            s3.download_file(s3_bucket, key, f'data/{filename}')\n",
    "\n",
    "# place to store data\n",
    "hist_data, sw, crss, meta = [],[], [], []\n",
    "colors = ['red', 'blue']\n",
    "\n",
    "# plot the tif\n",
    "f, ax = plt.subplots(nrows=1, ncols=len(scene_tifs), figsize=(18,10))\n",
    "for i in range(0,len(scene_tifs)):\n",
    "      filename = scene_tifs.iloc[i].file\n",
    "      software = scene_tifs.iloc[i].software\n",
    "      key = scene_tifs.iloc[i].Key\n",
    "\n",
    "      # assign crs to pyrosar\n",
    "      if 'pyrosar' in key:\n",
    "            print(f'Assigning EPSG:3031 to {filename}')\n",
    "            with rasterio.open(f'data/{filename}', 'r+') as rds:\n",
    "                  rds.crs = CRS.from_epsg(3031)\n",
    "\n",
    "      with rasterio.open(f'data/{filename}') as src:\n",
    "            data = src.read(1)\n",
    "            # covert from linear to db\n",
    "            data = 10*np.log10(data)\n",
    "            if 'pyrosar' in key:\n",
    "                  # covert no data from 0 to nan\n",
    "                  data[data==0] = np.nan\n",
    "            crss.append(src.meta['crs'])\n",
    "            print(f'{software} - {data.shape}')\n",
    "            #plt.figure(figsize = (10,6))\n",
    "            im = ax[i].imshow(data, vmin=-40, vmax=10, cmap='binary_r')\n",
    "            ax[i].set_title(f'{software}')\n",
    "            hist_data.append(data[(np.isfinite(data))])\n",
    "            sw.append(software)\n",
    "            meta.append(src.meta.copy())\n",
    "\n",
    "plt.suptitle(f'{scene}', y=0.9)\n",
    "cbar_ax = f.add_axes([0.95, 0.15, 0.04, 0.7])\n",
    "f.colorbar(im, cax=cbar_ax)\n",
    "plt.show()\n",
    "\n",
    "# plot the histogram \n",
    "for i in range(0,len(sw)):\n",
    "      u, std = np.mean(hist_data[i]), np.std(hist_data[i])\n",
    "      plt.hist(hist_data[i], \n",
    "               density=True,\n",
    "               bins=60, \n",
    "               alpha=0.5, \n",
    "               label=f'{sw[i]}; u={u:.3f}, std={std:.3f}', \n",
    "               color=colors[i],\n",
    "               histtype='step')\n",
    "\n",
    "plt.title(f'{scene}')\n",
    "plt.xlabel('Gamma0 RTC (dB)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Metdata and projections')\n",
    "for i,s in enumerate(sw):\n",
    "    print(s)\n",
    "    print(meta[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raster Difference Maps\n",
    "- Note differences may be due to geometric differences and not intensity\n",
    "- Be sure to inspect the pixel shift below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the scene geom in 4326\n",
    "asf_result = asf.granule_search([scene], asf.ASFSearchOptions(processingLevel='SLC'))[0]\n",
    "points = (asf_result.__dict__['umm']['SpatialExtent']['HorizontalSpatialDomain']\n",
    "                ['Geometry']['GPolygons'][0]['Boundary']['Points'])\n",
    "points = [(p['Longitude'],p['Latitude']) for p in points]\n",
    "scene_poly = Polygon(points)\n",
    "str(scene_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyrosar_file = scene_tifs[scene_tifs['software']=='pyrosar']['file'].iloc[0]\n",
    "opera_file = scene_tifs[scene_tifs['software']=='rtc-opera']['file'].iloc[0]\n",
    "# local files\n",
    "pyrosar_file = f'data/{pyrosar_file}'\n",
    "opera_file = f'data/{opera_file}'\n",
    "pyrosar = rioxarray.open_rasterio(pyrosar_file)\n",
    "opera = rioxarray.open_rasterio(opera_file)\n",
    "# clip by the scene geometry\n",
    "pyrosar_clipped = pyrosar.rio.clip([scene_poly], CRS.from_epsg(4326))\n",
    "opera_clipped = opera.rio.clip([scene_poly], CRS.from_epsg(4326))\n",
    "print(pyrosar_clipped.shape, opera_clipped.shape)\n",
    "# match the projection/transform/shape\n",
    "pyrosar_matched = pyrosar_clipped.rio.reproject_match(opera_clipped)\n",
    "print(pyrosar_matched.shape)\n",
    "# convert to db\n",
    "pyrosar_db = 10*np.log10(pyrosar_matched)\n",
    "opera_db = 10*np.log10(opera_clipped)\n",
    "# calculate the difference between the two images\n",
    "diff = pyrosar_db - opera_db\n",
    "# relative difference as a % of opera\n",
    "rel_deff = 100*(diff/opera_clipped)\n",
    "# save tifs\n",
    "pyrosar_db.rio.to_raster(f'data/{scene}_pyrosar_clipped.tif')\n",
    "opera_db.rio.to_raster(f'data/{scene}_opera_clipped.tif')\n",
    "diff.rio.to_raster(f'data/{scene}_diff_clipped.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample \n",
    "# upscale_factor = 0.1\n",
    "upscale_factor = False\n",
    "if upscale_factor:\n",
    "    new_width = int(pyrosar_db.rio.width * upscale_factor)\n",
    "    new_height = int(pyrosar_db.rio.height * upscale_factor)\n",
    "\n",
    "    pyrosar_db = pyrosar_db.rio.reproject(\n",
    "        pyrosar_db.rio.crs,\n",
    "        shape=(new_height, new_width),\n",
    "        resampling=Resampling.bilinear,\n",
    "    )\n",
    "\n",
    "    opera_db = opera_db.rio.reproject(\n",
    "        opera_db.rio.crs,\n",
    "        shape=(new_height, new_width),\n",
    "        resampling=Resampling.bilinear,\n",
    "    )\n",
    "\n",
    "    diff = pyrosar_db - opera_db\n",
    "    print(diff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_arr = np.array(diff)[np.array((np.isfinite(diff)))]\n",
    "print('Difference Stats')\n",
    "print(f'min: {stats_arr.min()}', \n",
    "      f'max: {stats_arr.max()}',\n",
    "      f'5th percentile: {np.percentile(stats_arr, 5)}',\n",
    "      f'90th percentile: {np.percentile(stats_arr, 95)}',\n",
    "      )\n",
    "\n",
    "arrs = [pyrosar_db, opera_db, diff]\n",
    "cmaps = ['binary_r','binary_r','bwr']\n",
    "scales = [[-40,10],[-40,10],[-1,1]]\n",
    "titles = ['pyrosar',\n",
    "          'opera-rtc',\n",
    "          'abs difference (pyrosar - opera-rtc)']\n",
    "\n",
    "f, ax = plt.subplots(nrows=4, ncols=1, figsize=(10,40))\n",
    "for i,arr in enumerate(arrs):\n",
    "      im = ax[i].imshow(arr[0], \n",
    "            vmin = scales[i][0], \n",
    "            vmax = scales[i][1],\n",
    "            cmap = cmaps[i])\n",
    "      ax[i].set_title(titles[i])\n",
    "      f.colorbar(im, ax=ax[i], label='decibels (dB)')\n",
    "      \n",
    "# plot the histogram\n",
    "colors = ['red','blue']\n",
    "for i in [0,1]:\n",
    "      # only get real values \n",
    "      hist_data = np.array(arrs[i])[\n",
    "            (np.isfinite(np.array(arrs[i])))\n",
    "            ]\n",
    "      u, std = np.mean(hist_data), np.std(hist_data)\n",
    "      ax[3].hist(hist_data, \n",
    "               density=True,\n",
    "               bins=60, \n",
    "               alpha=0.5, \n",
    "               label=f'{titles[i]}; u={u:.3f}, std={std:.3f}', \n",
    "               color=colors[i],\n",
    "               histtype='step')\n",
    "      ax[3].set_title('Pixel distribution (dB)')\n",
    "\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See pixel shift in small area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,x2,y1,y2 = 8600,9000,6600,7000 # full res\n",
    "#x1,x2,y1,y2 = 6500,6900,4600,5000 # full res\n",
    "#x1,x2,y1,y2 = 2000,2500,8600,9100 # full res\n",
    "if upscale_factor:\n",
    "    x1,x2,y1,y2 = [int(n*upscale_factor) for n in [x1,x2,y1,y2]] # adjust for scaling\n",
    "pyrosar_snip = pyrosar_db[0][y1:y2,x1:x2]\n",
    "opera_snip = opera_db[0][y1:y2,x1:x2]\n",
    "pyrosar_snip = pyrosar_db[0][y1:y2,x1:x2]\n",
    "animation = make_gif([opera_snip, pyrosar_snip], vmin=-40, vmax=10)\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate Opera H5 Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene  = scenes[0]\n",
    "h5_file_s3 = f'rtc-opera/{dem}/{scene}/OPERA_L2_RTC-{scene}.h5'\n",
    "h5_file_local = f'data/OPERA_L2_RTC-{scene}.h5'\n",
    "s3.download_file(s3_bucket, h5_file_s3, h5_file_local)\n",
    "h5_data = h5py.File(h5_file_local,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(h5_data['identification']))\n",
    "list(h5_data['data'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanpercentile(h5_data['data']['numberOfLooks'][:],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1['metadata']['processingInformation']['parameters'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in f1['data'].keys():\n",
    "    print(x + ' : ', f1['data'][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmax(f1['data']['numberOfLooks'][:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyroSAR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
