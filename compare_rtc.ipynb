{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Sentinel-1 RTC products from different software"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was produced as part of the Digital Earth Antarctica (DEAnt) evaluation of different software options to produce SAR RTC data. Four options have been compares using 'on-the-fly' (otf) pipelines developed for each software. The four softwares options of interest are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import json\n",
    "import rasterio\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.enums import Resampling\n",
    "import rioxarray\n",
    "import asf_search as asf\n",
    "from shapely.geometry import Polygon\n",
    "from celluloid import Camera # getting the camera\n",
    "from IPython.display import HTML\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gif(imgs, vmin, vmax, title=''):\n",
    "    fig, ax = plt.subplots() # make it bigger\n",
    "    camera = Camera(fig)# the camera gets our figure\n",
    "    for i,img in enumerate(imgs):\n",
    "        im = ax.imshow(img,\n",
    "                  vmin=vmin,\n",
    "                  vmax=vmax) # plotting\n",
    "        ax.set_title(f'{title}')\n",
    "        camera.snap()\n",
    "    animation = camera.animate()\n",
    "    return animation\n",
    "\n",
    "def assign_crs(tif_path, crs):\n",
    "    with rasterio.open(tif_path, 'r+') as rds:\n",
    "        rds.crs = CRS.from_epsg(crs)\n",
    "\n",
    "def plot_tifs(\n",
    "    tif_1, \n",
    "    tif_2, \n",
    "    titles= ['arr_1', 'arr_2'],\n",
    "    suptitle='suptitle',\n",
    "    convert_dB = True,\n",
    "    scale=[-40,10],\n",
    "    cmap = 'binary_r',\n",
    "    save_path=''):\n",
    "\n",
    "    # place to store data\n",
    "    hist_data, crss, meta = [],[], []\n",
    "    colors = ['red', 'blue']\n",
    "\n",
    "    # plot the tif\n",
    "    f, ax = plt.subplots(nrows=1, ncols=2, figsize=(18,10))\n",
    "    for i, tif in enumerate([tif_1, tif_2]):\n",
    "        with rasterio.open(tif.local_file) as src:\n",
    "                data = src.read(1)\n",
    "                nodata = src.nodata\n",
    "                # covert from linear to db\n",
    "                if convert_dB:\n",
    "                    data = 10*np.log10(data)\n",
    "                # covert no data to nan\n",
    "                data[data==nodata] = np.nan\n",
    "                crss.append(src.meta['crs'])\n",
    "                im = ax[i].imshow(data, cmap=cmap, vmin=scale[0], vmax=scale[1])\n",
    "                ax[i].set_title(f'{titles[i]}')\n",
    "                hist_data.append(data[(np.isfinite(data))])\n",
    "                meta.append(src.meta.copy())\n",
    "\n",
    "    plt.suptitle(f'{suptitle}', y=0.9)\n",
    "    cbar_ax = f.add_axes([0.95, 0.15, 0.04, 0.7])\n",
    "    f.colorbar(im, cax=cbar_ax)\n",
    "    plt.show()\n",
    "\n",
    "    # plot the histogram \n",
    "    for i in [0,1]:\n",
    "        u, std = np.mean(hist_data[i]), np.std(hist_data[i])\n",
    "        plt.hist(hist_data[i], \n",
    "                density=True,\n",
    "                bins=60, \n",
    "                alpha=0.5, \n",
    "                label=f'{titles[i]}; u={u:.3f}, std={std:.3f}', \n",
    "                color=colors[i],\n",
    "                histtype='step')\n",
    "\n",
    "    plt.title(f'{suptitle}')\n",
    "    plt.xlabel('Gamma0 RTC')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    for i, tif in enumerate([tif_1, tif_2]):\n",
    "        print(tif)\n",
    "        for k in meta[i].keys():\n",
    "            print(f'{k} : {meta[i][k]}')\n",
    "        print('\\n')\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "\n",
    "    \n",
    "def plot_difference_maps(\n",
    "    arr_1, \n",
    "    arr_2, \n",
    "    titles=['arr_1','arr_2','diff (arr_1 - arr_2)'],\n",
    "    scales = [[-40,10],[-40,10],[-1,1]],\n",
    "    ylabels=['decibels (dB)','decibels (dB)','decibels (dB)'],\n",
    "    save_path=''):\n",
    "    \n",
    "    diff = arr_1 - arr_2\n",
    "    arrs = [arr_1, arr_2, diff]\n",
    "    stats_arr = np.array(diff)[np.array((np.isfinite(diff)))]\n",
    "    print('Difference Stats')\n",
    "    print(f'min: {stats_arr.min()}', \n",
    "        f'max: {stats_arr.max()}',\n",
    "        f'mean: {stats_arr.mean()}',\n",
    "        f'median: {np.percentile(stats_arr, 50)}',\n",
    "        f'5th percentile: {np.percentile(stats_arr, 5)}',\n",
    "        f'90th percentile: {np.percentile(stats_arr, 95)}',\n",
    "        )\n",
    "\n",
    "    cmaps = ['binary_r','binary_r','bwr']\n",
    "\n",
    "    f, ax = plt.subplots(nrows=4, ncols=1, figsize=(10,40))\n",
    "    for i,arr in enumerate(arrs):\n",
    "        im = ax[i].imshow(arr[0], \n",
    "                vmin = scales[i][0], \n",
    "                vmax = scales[i][1],\n",
    "                cmap = cmaps[i])\n",
    "        ax[i].set_title(titles[i])\n",
    "        f.colorbar(im, ax=ax[i], label=ylabels[i])\n",
    "        \n",
    "    # plot the histogram\n",
    "    colors = ['red','blue']\n",
    "    for i in [0,1]:\n",
    "        # only get real values \n",
    "        hist_data = np.array(arrs[i])[\n",
    "                (np.isfinite(np.array(arrs[i])))\n",
    "                ]\n",
    "        u, std = np.mean(hist_data), np.std(hist_data)\n",
    "        ax[3].hist(hist_data, \n",
    "                density=True,\n",
    "                bins=60, \n",
    "                alpha=0.5, \n",
    "                label=f'{titles[i]}; u={u:.3f}, std={std:.3f}', \n",
    "                color=colors[i],\n",
    "                histtype='step')\n",
    "        ax[3].set_title('Pixel distribution')\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general structure for scenes in s3\n",
    "# s3_bucket/software/dem/scene/scene_files\n",
    "s3_bucket = 'deant-data-public-dev'\n",
    "s3_bucket_link = 'https://deant-data-public-dev.s3.ap-southeast-2.amazonaws.com/'\n",
    "\n",
    "scenes = [\n",
    "        'S1B_IW_SLC__1SSH_20190223T222639_20190223T222706_015079_01C2E9_1D63',\n",
    "        'S1A_IW_SLC__1SSH_20190605T222724_20190605T222751_027550_031BE1_AD3A',\n",
    "        'S1A_IW_SLC__1SSH_20190926T124734_20190926T124804_029192_0350B9_FA6B',\n",
    "        'S1A_IW_SLC__1SSH_20230127T142750_20230127T142817_046970_05A22F_17F7',\n",
    "        'S1B_IW_SLC__1SSH_20190315T195015_20190315T195045_015369_01CC73_DB8B',\n",
    "        'S1B_IW_SLC__1SSH_20210223T233056_20210223T233124_025740_031194_E7BE',\n",
    "        'S1B_IW_SLC__1SSH_20210228T035005_20210228T035033_025801_03138F_8CB2',\n",
    "]\n",
    "softwares = ['pyrosar','rtc-opera','hyp3-gamma', 'S1_NRB']\n",
    "dems = ['glo_30','REMA_32']\n",
    "\n",
    "# get crededentials for AWS\n",
    "with open('aws_credentials.txt') as f:\n",
    "    ACCESS_ID, ACCESS_KEY = f.readlines()\n",
    "    ACCESS_ID = ACCESS_ID.strip()\n",
    "    ACCESS_KEY = ACCESS_KEY.strip()\n",
    "\n",
    "# setup s3\n",
    "s3 = boto3.client('s3', \n",
    "                        region_name='ap-southeast-2',\n",
    "                        aws_access_key_id=ACCESS_ID,\n",
    "                        aws_secret_access_key= ACCESS_KEY)\n",
    "\n",
    "# make data directory to store local files\n",
    "os.makedirs('data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show example scene files for software"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Products**\n",
    "- RTC products are stored in the s3 bucket specified above\n",
    "- The general pattern for the products is : ```software/dem/crs/scene/files```\n",
    "\n",
    "**Projections**\n",
    "- pyrosar and rtc-opera are projected in 3031 polar steregraphic coordinates \n",
    "- hype-gamma and S1_NRB products are provided in UTM zone projections (output crs cannot be specified)\n",
    "- For a fair comparison, products should be compared in the same projection\n",
    "\n",
    "**Data**\n",
    "- Naming convention for rtc backscatter differs for each product\n",
    "\n",
    "**Metadata**\n",
    "- Metadata products are stored differently between products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = []\n",
    "for software in softwares:\n",
    "    for dem in dems:\n",
    "        params = {\n",
    "            \"Bucket\": f'{s3_bucket}',\n",
    "            \"Prefix\": f'{software}/{dem}'\n",
    "        }\n",
    "        objects = s3.list_objects_v2(**params)\n",
    "        if 'Contents' in objects.keys():\n",
    "            data = objects['Contents']\n",
    "            file_list.extend([x for x in objects['Contents']])\n",
    "\n",
    "# save all of the files in a dataframe for east of searching\n",
    "df_s3 = pd.DataFrame.from_records(file_list)\n",
    "df_s3[['software','dem','crs','scene','file']] = df_s3['Key'].str.split('/', n=4, expand=True)\n",
    "df_s3.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare total timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit to single dem and proj\n",
    "df_timing_files = df_s3[(\n",
    "    (df_s3['file'].str.contains('_timing.json'))\n",
    "    #& (df_s3['dem']==dem)\n",
    "    #& (df_s3['crs']==proj\n",
    "    )]\n",
    "df_timing_files.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_data = []\n",
    "for i in range(0,len(df_timing_files)):\n",
    "    timing_file = df_timing_files.iloc[i].Key\n",
    "    print(timing_file)\n",
    "    try:\n",
    "        s3.download_file(s3_bucket, timing_file, 'tmp.json')\n",
    "        with open('tmp.json') as json_file:\n",
    "            data = json.load(json_file)\n",
    "            data['software'] = df_timing_files.iloc[i].software\n",
    "            data['scene'] = df_timing_files.iloc[i].scene\n",
    "        timing_data.append(data)\n",
    "        print(f'downloaded: {timing_file}')\n",
    "    except:\n",
    "        print(f'no timing file: {timing_file}')\n",
    "\n",
    "os.remove('tmp.json')\n",
    "df_timing = pd.DataFrame.from_records(timing_data, index=['software','scene'])\n",
    "\n",
    "# gamma values are in list for some reason\n",
    "for col in list(df_timing):\n",
    "    df_timing[col] = df_timing[col].apply(lambda x : x[0] if isinstance(x,list) else x)\n",
    "\n",
    "# min timing filter to remove false information\n",
    "min_time = 500\n",
    "df_timing = df_timing[df_timing['Total']>min_time]\n",
    "\n",
    "# plot mean time by software\n",
    "sw_count = df_timing.groupby('software').size()\n",
    "ax = (df_timing.groupby('software').mean()\n",
    " .drop(columns=['Total'])\n",
    " .plot.bar(stacked=True))\n",
    "ax.set_xlabel('Software')\n",
    "ax.set_ylabel('Time (seconds)')\n",
    "ax.set_title(f'Software Processing Mean Times (DEM upsampling=2)')\n",
    "print(sw_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Scenes\n",
    "**Differences**\n",
    "- Treatment of burst overlaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditions for the comparison\n",
    "- we want a single dependant variable to compare the scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_s3.groupby(['scene','software'])['crs'].unique()\n",
    "df_s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the settings for the comparison\n",
    "# compare 1 scene agains a single dependant variable (e.g. dem, software, proj)\n",
    "scene = 'S1A_IW_SLC__1SSH_20230116T100627_20230116T100655_046807_059CB3_FCC7'\n",
    "dependant_var = 'software'\n",
    "dependant_vals = ['pyrosar','hyp3-gamma']\n",
    "independant_var1 = 'dem'\n",
    "independant_val1 = 'glo_30'\n",
    "target_crs = 3031\n",
    "\n",
    "print(f'Comparing scenes with varying {dependant_var} : {dependant_vals}')\n",
    "print(f'Keeping {independant_var1} fixed: {independant_val1}')\n",
    "\n",
    "df_comparison = df_s3[(\n",
    "    (df_s3[dependant_var].isin(dependant_vals))\n",
    "    & (df_s3[independant_var1] == independant_val1)\n",
    "    & (df_s3['scene'] == scene)\n",
    ")]\n",
    "\n",
    "scene_tifs = df_comparison[(\n",
    "      (df_comparison.file.str.contains('rtc|HH')) &\n",
    "      (df_comparison.file.str.endswith('tif'))\n",
    "      )]\n",
    "scene_dems = df_comparison[(df_comparison.file.str.endswith('_dem.tif'))]\n",
    "print(f'{len(scene_tifs)} scene tifs found meeting conditions')\n",
    "print(f'{len(scene_dems)} scene dems found meeting conditions')\n",
    "assert len(scene_tifs)==2, 'just two scenes meeting conditions are required for comparison'\n",
    "assert len(scene_tifs)==2, 'just two dems meeting conditions are required for comparison'\n",
    "\n",
    "# determine which scenes need to be reprojected\n",
    "scene_tifs['reproject'] = scene_tifs['crs'].apply(lambda x : False if str(x) == str(target_crs) else True)\n",
    "scene_tifs[['software','dem','crs','Size','reproject','file']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the tifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download tifs and store locally\n",
    "download = False\n",
    "if download:\n",
    "    for i in range(0,len(scene_tifs)):\n",
    "        key = scene_tifs.iloc[i].Key\n",
    "        filename = scene_tifs.iloc[i].file\n",
    "        print(f'downloading {filename}')\n",
    "        s3.download_file(s3_bucket, key, f'data/tifs/{filename}')\n",
    "scene_tifs['local_file'] = scene_tifs['file'].apply(lambda x : f'data/tifs/{x}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of raw outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the two tiffs side by side with native projections, shapes etc\n",
    "tif_1_data = scene_tifs.iloc[0]\n",
    "tif_2_data = scene_tifs.iloc[1]\n",
    "\n",
    "plot_tifs(\n",
    "    tif_1_data, \n",
    "    tif_2_data, \n",
    "    titles= dependant_vals,\n",
    "    suptitle=f'{scene}',\n",
    "    convert_dB = True,\n",
    "    cmap = 'binary_r',\n",
    "    scale=[-40,10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raster Difference Maps\n",
    "- Project rasters to the same resolutions and shapes to enable a direct difference\n",
    "- Note differences may be due to geometric differences and not intensity\n",
    "- Be sure to inspect the pixel shift below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the scene geom in 4326\n",
    "asf.constants.CMR_TIMEOUT = 45\n",
    "asf_result = asf.granule_search([scene], asf.ASFSearchOptions(processingLevel='SLC'))[0]\n",
    "points = (asf_result.__dict__['umm']['SpatialExtent']['HorizontalSpatialDomain']\n",
    "                ['Geometry']['GPolygons'][0]['Boundary']['Points'])\n",
    "points = [(p['Longitude'],p['Latitude']) for p in points]\n",
    "scene_poly = Polygon(points)\n",
    "str(scene_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local files\n",
    "local_tif_1_path = tif_1_data.local_file\n",
    "local_tif_2_path = tif_2_data.local_file\n",
    "#assign_crs(local_tif_1_path, 3031) # assign missing crs to pyrosar...\n",
    "print(local_tif_1_path)\n",
    "print(local_tif_2_path)\n",
    "tif_1_f = rioxarray.open_rasterio(local_tif_1_path)\n",
    "tif_2_f = rioxarray.open_rasterio(local_tif_2_path)\n",
    "# clip by the scene geometry\n",
    "tif_1_clipped = tif_1_f.rio.clip([scene_poly], CRS.from_epsg(4326))\n",
    "tif_2_clipped = tif_2_f.rio.clip([scene_poly], CRS.from_epsg(4326))\n",
    "del tif_1_f\n",
    "del tif_2_f\n",
    "print(tif_1_clipped.shape, tif_2_clipped.shape)\n",
    "# match the projection/transform/shape\n",
    "tif_1_matched = tif_1_clipped.rio.reproject_match(tif_2_clipped)\n",
    "print(tif_1_matched.shape)\n",
    "# convert to db\n",
    "tif_1_db = 10*np.log10(tif_1_matched)\n",
    "tif_2_db = 10*np.log10(tif_2_clipped)\n",
    "# calculate the difference between the two images\n",
    "diff = tif_1_db - tif_2_db\n",
    "# relative difference as a % of tif_2\n",
    "rel_deff = 100*(diff/tif_2_clipped)\n",
    "# save tifs\n",
    "tif_1_db.rio.to_raster(f'data/tifs/{scene}_{dependant_vals[0]}_clipped.tif')\n",
    "tif_2_db.rio.to_raster(f'data/tifs/{scene}_{dependant_vals[1]}_clipped.tif')\n",
    "diff.rio.to_raster(f'data/tifs/{scene}_diff_clipped.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample \n",
    "# upscale_factor = 0.1\n",
    "upscale_factor = False\n",
    "if upscale_factor:\n",
    "    new_width = int(tif_1_db.rio.width * upscale_factor)\n",
    "    new_height = int(tif_1_db.rio.height * upscale_factor)\n",
    "\n",
    "    tif_1_db = tif_1_db.rio.reproject(\n",
    "        tif_1_db.rio.crs,\n",
    "        shape=(new_height, new_width),\n",
    "        resampling=Resampling.bilinear,\n",
    "    )\n",
    "\n",
    "    tif_2_db = tif_2_db.rio.reproject(\n",
    "        tif_2_db.rio.crs,\n",
    "        shape=(new_height, new_width),\n",
    "        resampling=Resampling.bilinear,\n",
    "    )\n",
    "\n",
    "    diff = tif_1_db - tif_2_db\n",
    "    print(diff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [[-40,10],[-40,10],[-1,1]]\n",
    "titles = [f'{dependant_vals[0]}',\n",
    "          f'{dependant_vals[1]}',\n",
    "          f'abs difference ({dependant_vals[0]} - {dependant_vals[1]}-rtc)']\n",
    "plot_difference_maps(\n",
    "      tif_1_db, \n",
    "      tif_2_db,\n",
    "      titles=titles,\n",
    "      scales=scales,\n",
    "      save_path=f'data/compare-rtc/{scene}_{dependant_vals[0]}_vs_{dependant_vals[1]}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See pixel shift in small area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x1,x2,y1,y2 = 8600,9000,6600,7000 # full res\n",
    "#x1,x2,y1,y2 = 3400,4000,9400,10000 # full res\n",
    "x1,x2,y1,y2 = 6500,6900,4600,5000 # full res\n",
    "#x1,x2,y1,y2 = 2000,2500,8600,9100 # full res\n",
    "#x1,x2,y1,y2 = 7000,7500,3800,4300# full res\n",
    "if upscale_factor:\n",
    "    x1,x2,y1,y2 = [int(n*upscale_factor) for n in [x1,x2,y1,y2]] # adjust for scaling\n",
    "tif_1_snip = tif_1_db[0][y1:y2,x1:x2]\n",
    "tif_2_snip = tif_2_db[0][y1:y2,x1:x2]\n",
    "animation = make_gif(\n",
    "    [tif_2_snip, tif_1_snip], \n",
    "    vmin=-40, \n",
    "    vmax=10, \n",
    "    title=f'{dependant_vals[0]}_vs_{dependant_vals[1]}')\n",
    "animation.save(f'data/compare-rtc/{scene}_{dependant_vals[0]}_vs_{dependant_vals[1]}.gif')\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corestister the Images with Arosics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arosics\n",
    "# img_trg is the one that is shifted\n",
    "coreg = arosics.CoReg.COREG(\n",
    "    im_ref=f'data/tifs/{scene}_{dependant_vals[1]}_clipped.tif', \n",
    "    im_tgt=f'data/tifs/{scene}_{dependant_vals[0]}_clipped.tif', \n",
    "    path_out=f'data/tifs/{scene}_{dependant_vals[0]}_clipped_aligned.tif', \n",
    "    fmt_out='GTIFF',\n",
    "    align_grids=True)\n",
    "res = coreg.correct_shifts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_1_db = rioxarray.open_rasterio(f'data/tifs/{scene}_{dependant_vals[0]}_clipped_aligned.tif')\n",
    "tif_2_db = rioxarray.open_rasterio(f'data/tifs/{scene}_{dependant_vals[1]}_clipped.tif')\n",
    "\n",
    "tif_1_snip = tif_1_db[0][y1:y2,x1:x2]\n",
    "tif_2_snip = tif_2_db[0][y1:y2,x1:x2]\n",
    "animation = make_gif(\n",
    "    [tif_2_snip, \n",
    "    tif_1_snip], \n",
    "    vmin=-40, \n",
    "    vmax=10, \n",
    "    title=f'{dependant_vals[0]}_vs_{dependant_vals[1]}_aligned')\n",
    "animation.save(f'data/compare-rtc/{scene}_{dependant_vals[0]}_vs_{dependant_vals[1]}_aligned.gif')\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [[-40,10],[-40,10],[-1,1]]\n",
    "titles = [f'{dependant_vals[0]}',\n",
    "          f'{dependant_vals[1]}',\n",
    "          f'abs difference ({dependant_vals[0]} - {dependant_vals[1]})']\n",
    "plot_difference_maps(\n",
    "      tif_1_db, \n",
    "      tif_2_db,\n",
    "      titles=titles,\n",
    "      scales=scales,\n",
    "      save_path=f'data/compare-rtc/{scene}_{dependant_vals[0]}_vs_{dependant_vals[1]}_aligned.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the DEMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download tifs and store locally\n",
    "local_dems = []\n",
    "download = False\n",
    "if download:\n",
    "      for i in range(0,len(scene_dems)):\n",
    "            key = scene_dems.iloc[i].Key\n",
    "            filename = scene_dems.iloc[i].file\n",
    "            sw = scene_dems.iloc[i].software\n",
    "            s3.download_file(s3_bucket, key, f'data/tifs/{sw}_{filename}')\n",
    "            local_dems.append(f'data/tifs/{sw}_{filename}')\n",
    "local_dems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear mem\n",
    "tif_1_db = tif_2_db = coreg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the dems\n",
    "tif_1_dem = rioxarray.open_rasterio(f'data/tif_1_{scene}_dem.tif')\n",
    "tif_2_dem = rioxarray.open_rasterio(f'data/rtc-tif_2_{scene}_dem.tif')\n",
    "# clip by scene geom\n",
    "tif_1_dem = tif_1_dem.rio.clip([scene_poly], CRS.from_epsg(4326))\n",
    "tif_2_dem = tif_2_dem.rio.clip([scene_poly], CRS.from_epsg(4326))\n",
    "print(tif_1_dem.shape, tif_2_dem.shape)\n",
    "# match the projection/transform/shape of the dems\n",
    "tif_1_dem = tif_1_dem.rio.reproject_match(tif_2_dem)\n",
    "print(tif_1_dem.shape, tif_2_dem.shape)\n",
    "\n",
    "# convert to np arrays\n",
    "tif_1_dem = np.array(tif_1_dem)\n",
    "tif_2_dem = np.array(tif_2_dem)\n",
    "tif_1_dem[(tif_1_dem==-9999)] = np.nan # replace nodata with -9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try and adjust for pixel size (30m/20)\n",
    "x1,x2,y1,y2 = (np.array((x1,x2,y1,y2))*(2/3)).astype(int)\n",
    "pyrosar_snip = pyrosar_dem[0][y1:y2,x1:x2]\n",
    "opera_snip = opera_dem[0][y1:y2,x1:x2]\n",
    "# replace pyrosar nodata of -9999 with nans\n",
    "animation = make_gif([opera_snip, pyrosar_snip], vmin=None, vmax=None)\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [[None,None],[None,None],[None,None]]\n",
    "titles = ['pyrosar dem (glo-30)',\n",
    "          'opera-rtc dem (glo-30)',\n",
    "          'abs difference (pyrosar - opera-rtc)']\n",
    "ylabels = ['elevation (m)', 'elevation (m)', 'difference (m)']\n",
    "plot_difference_maps(\n",
    "      pyrosar_dem, \n",
    "      opera_dem,\n",
    "      titles=titles,\n",
    "      scales=scales,\n",
    "      ylabels=ylabels\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_extra_points_along_boundary(bbox, delta=0.1):\n",
    "    \"\"\"\n",
    "    Generate points along the boundary of a bounding box.\n",
    "\n",
    "    Parameters:\n",
    "    - bbox: Tuple of four coordinates (x_min, y_min, x_max, y_max).\n",
    "    - delta: distance between points along the bounding box sides \n",
    "\n",
    "    Returns:\n",
    "    - List of points [(x1, y1), (x2, y2), ...] along the boundary.\n",
    "    \"\"\"\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    # Generate points along the top side\n",
    "    top_side = [(x, y_max) for x in list(np.arange(x_min, x_max, delta)) + [x_max]]    \n",
    "    # Generate points along the right side\n",
    "    right_side = [(x_max, y) for y in list(np.arange(y_max - delta, y_min-delta, -delta)) + [y_min-delta]]\n",
    "    # Generate points along the bottom side\n",
    "    bottom_side = [(x, y_min) for x in list(np.arange(x_max - delta, x_min-delta, -delta)) + [x_min-delta]]\n",
    "    list(np.arange(y_min + delta, y_max, delta)) + [y_max]\n",
    "    # Generate points along the left side\n",
    "    left_side = [(x_min, y) for y in list(np.arange(y_min + delta, y_max, delta)) + [y_max]]\n",
    "    # Combine all sides' points\n",
    "    all_points = top_side + right_side + bottom_side + left_side\n",
    "    return all_points\n",
    "\n",
    "# Example usage:\n",
    "bounding_box = (150, -75, 160, -70)\n",
    "points_along_boundary = generate_points_along_boundary(bounding_box)\n",
    "print(points_along_boundary)\n",
    "Polygon(points_along_boundary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyroSAR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
