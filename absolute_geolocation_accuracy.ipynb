{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RTC Product Validation: Point Target Absolute Geolocation Evaluation\n",
    "\n",
    "Author: Alex Bradley\n",
    "\n",
    "This notebook uses known corner reflector locations to determine the geometric accuracy of RTC products.\n",
    "\n",
    "This notebook is a generalisation built on the work of Alex Lewandowski & Franz J Meyer; Alaska Satellite Facility, University of Alaska Fairbanks. \n",
    "\n",
    "This notebook has been adapted from :  https://github.com/OPERA-Cal-Val/calval-RTC/blob/main/absolute_geolocation_evaluation/absolute_location_evaluation.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime as dt\n",
    "import math\n",
    "from pathlib import Path\n",
    "import re\n",
    "import requests\n",
    "import warnings\n",
    "import os\n",
    "import re\n",
    "import ntpath\n",
    "\n",
    "import asf_search\n",
    "import fiona \n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import lmfit\n",
    "from lmfit.lineshapes import gaussian2d, lorentzian\n",
    "from lmfit import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyproj\n",
    "from pyproj import Proj, CRS\n",
    "import rasterio\n",
    "from shapely import geometry\n",
    "from shapely.geometry import Polygon\n",
    "import shapely.wkt\n",
    "from urllib.request import urlretrieve\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ripping fucntions from isce3 source code to remove reliance on having full project installed...\n",
    "\n",
    "def estimate_frequency(z):\n",
    "    # https://github.com/isce-framework/isce3/blob/develop/python/packages/isce3/cal/point_target_info.py\n",
    "    cx = np.sum(z[:, 1:] * z[:, :-1].conj())\n",
    "    cy = np.sum(z[1:, :] * z[:-1, :].conj())\n",
    "    return np.angle([cx, cy])\n",
    "\n",
    "\n",
    "def shift_frequency(z, fx, fy):\n",
    "    # https://github.com/isce-framework/isce3/blob/develop/python/packages/isce3/cal/point_target_info.py\n",
    "    x = np.arange(z.shape[1])\n",
    "    y = np.arange(z.shape[0])\n",
    "    z *= np.exp(1j * fx * x)[None,:]\n",
    "    z *= np.exp(1j * fy * y)[:,None]\n",
    "    return z\n",
    "\n",
    "def oversample(x, nov, baseband=False, return_slopes=False):\n",
    "    # https://github.com/isce-framework/isce3/blob/develop/python/packages/isce3/cal/point_target_info.py\n",
    "    m, n = x.shape\n",
    "    assert m == n\n",
    "\n",
    "    if not baseband:\n",
    "        # shift the data to baseband\n",
    "        fx, fy = estimate_frequency(x)\n",
    "        x = shift_frequency(x, -fx, -fy)\n",
    "\n",
    "    X = np.fft.fft2(x)\n",
    "    # Zero-pad high frequencies in the spectrum.\n",
    "    Y = np.zeros((n * nov, n * nov), dtype=X.dtype)\n",
    "    n2 = n // 2\n",
    "    Y[:n2, :n2] = X[:n2, :n2]\n",
    "    Y[-n2:, -n2:] = X[-n2:, -n2:]\n",
    "    Y[:n2, -n2:] = X[:n2, -n2:]\n",
    "    Y[-n2:, :n2] = X[-n2:, :n2]\n",
    "    # Split Nyquist bins symmetrically.\n",
    "    assert n % 2 == 0\n",
    "    Y[:n2, n2] = Y[:n2, -n2] = 0.5 * X[:n2, n2]\n",
    "    Y[-n2:, n2] = Y[-n2:, -n2] = 0.5 * X[-n2:, n2]\n",
    "    Y[n2, :n2] = Y[-n2, :n2] = 0.5 * X[n2, :n2]\n",
    "    Y[n2, -n2:] = Y[-n2, -n2:] = 0.5 * X[n2, -n2:]\n",
    "    Y[n2, n2] = Y[n2, -n2] = Y[-n2, n2] = Y[-n2, -n2] = 0.25 * X[n2, n2]\n",
    "    # Back to time domain.\n",
    "    y = np.fft.ifft2(Y)\n",
    "    # NOTE account for scaling of different-sized DFTs.\n",
    "    y *= nov ** 2\n",
    "\n",
    "    if not baseband:\n",
    "        # put the phase back on\n",
    "        y = shift_frequency(y, fx / nov, fy / nov)\n",
    "\n",
    "    y = np.asarray(y, dtype=x.dtype)\n",
    "    if return_slopes:\n",
    "        return (y, fx, fy)\n",
    "    return y\n",
    "\n",
    "def oversample_slc(slc,sampling=1,y=None,x=None):\n",
    "    # https://github.com/OPERA-Cal-Val/calval-RTC/blob/main/absolute_geolocation_evaluation/src/ALE_utils.py\n",
    "    if y is None:\n",
    "        y = np.arange(slc.shape[0])\n",
    "    if x is None:\n",
    "        x = np.arange(slc.shape[1])\n",
    "\n",
    "    [rows, cols] = np.shape(slc)\n",
    "    \n",
    "    slcovs = oversample(slc,sampling, baseband=True)\n",
    "\n",
    "    y_orign_step = y[1]-y[0]\n",
    "    y_ovs_step = y_orign_step/sampling\n",
    "    x_orign_step = x[1]-x[0]\n",
    "    x_ovs_step = x_orign_step/sampling\n",
    "\n",
    "    y = np.arange(y[0],y[-1]+y_orign_step,y_ovs_step)\n",
    "    x = np.arange(x[0],x[-1]+x_orign_step,x_ovs_step)\n",
    "\n",
    "    return slcovs,y,x\n",
    "\n",
    "def findCR(data,y,x,x_bound=[-np.inf,np.inf],y_bound=[-np.inf,np.inf],method=\"sinc\"):\n",
    "    # https://github.com/OPERA-Cal-Val/calval-RTC/blob/main/absolute_geolocation_evaluation/src/ALE_utils.py\n",
    "    '''\n",
    "    Find the location of CR with fitting\n",
    "    '''\n",
    "    max_ind = np.argmax(data)\n",
    "    max_data = data[max_ind]\n",
    "    \n",
    "    def _sinc2D(x,x0,y0,a,b,c):\n",
    "        return c*np.sinc(a*(x[0]-x0))*np.sinc(b*(x[1]-y0))\n",
    "    \n",
    "    def _para2D(x,x0,y0,a,b,c,d):\n",
    "        return a*(x[0]-x0)**2+b*(x[1]-y0)**2+c*(x[0]-x0)*(x[1]-y0)+d\n",
    "\n",
    "    if method == \"sinc\":\n",
    "        # using sinc function for fitting \n",
    "        xdata = np.vstack((x,y))\n",
    "        p0 = [x[max_ind],y[max_ind],0.7,0.7,max_data]\n",
    "        bounds = ([x_bound[0],y_bound[0],0,0,0],[x_bound[1],y_bound[1],1,1,np.inf])\n",
    "        popt = scipy.optimize.curve_fit(_sinc2D,xdata,data,p0=p0,bounds=bounds)[0]\n",
    "        xloc = popt[0]; yloc = popt[1]\n",
    "    elif method == \"para\":\n",
    "        #using paraboloid function for fitting\n",
    "        xdata = np.vstack((x,y))\n",
    "        p0 = [x[max_ind],y[max_ind],-1,-1,1,1]\n",
    "        bounds = ([x_bound[0],y_bound[0],-np.inf,-np.inf,-np.inf,0],[x_bound[1],y_bound[1],0,0,np.inf,np.inf])\n",
    "        popt = scipy.optimize.curve_fit(_para2D,xdata,data,p0=p0,bounds=bounds)[0]\n",
    "        xloc = popt[0]; yloc = popt[1]\n",
    "\n",
    "    return yloc,xloc\n",
    "\n",
    "def transform_polygon(src_crs, dst_crs, geometry, always_xy=True):\n",
    "    src_crs = pyproj.CRS(f\"EPSG:{src_crs}\")\n",
    "    dst_crs = pyproj.CRS(f\"EPSG:{dst_crs}\") \n",
    "    transformer = pyproj.Transformer.from_crs(src_crs, dst_crs, always_xy=always_xy)\n",
    "     # Transform the polygon's coordinates\n",
    "    transformed_exterior = [\n",
    "        transformer.transform(x, y) for x, y in geometry.exterior.coords\n",
    "    ]\n",
    "    # Create a new Shapely polygon with the transformed coordinates\n",
    "    transformed_polygon = Polygon(transformed_exterior)\n",
    "    return transformed_polygon\n",
    "\n",
    "def assign_crs(tif_path, crs):\n",
    "    with rasterio.open(tif_path, 'r+') as rds:\n",
    "        rds.crs = CRS.from_epsg(crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Select RTC Products over Validation Sites\n",
    "These should be a local files that covers a roi where corner reflectors are located\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data/geolocation'\n",
    "tif_folder = 'data/tifs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Australian CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tif_path = f'{tif_folder}/S1A_IW_20220111T192213_DVP_RTC20_G_gpuned_396E_VV.tif'\n",
    "# s1_name = 'S1A_IW_SLC__1SDV_20220111T192213_20220111T192240_041417_04ECBD_9F3B'\n",
    "# tif_path = f'{tif_folder}/S1A_IW_20220123T192213_DVP_RTC20_G_gpuned_2456_VV.tif'\n",
    "# s1_name = 'S1A_IW_SLC__1SDV_20220123T192213_20220123T192240_041592_04F283_9D0E'\n",
    "# tif_path = f'{tif_folder}/S1A_IW_20220116T083314_SHP_RTC20_G_gpuned_8BA3_HH.tif'\n",
    "# s1_name = 'S1A_IW_SLC__1SSH_20220116T083314_20220116T083342_041483_04EED2_DB08'\n",
    "# ProdID = 'hyp3-gamma'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maitri Station Antarctica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s1_name = 'S1B_IW_SLC__1SSH_20190315T195015_20190315T195045_015369_01CC73_DB8B'\n",
    "\n",
    "#tif_path = f'{tif_folder}/OPERA_L2_RTC-S1B_IW_SLC__1SSH_20190315T195015_20190315T195045_015369_01CC73_DB8B_HH.tif'\n",
    "#ProdID = 'rtc-opera'\n",
    "\n",
    "#tif_path = 'data/tifs/S1B__IW___A_20190315T195015_HH_gamma0-rtc.tif'\n",
    "#ProdID = 'pyrosar'\n",
    "\n",
    "#tif_path = 'data/tifs/S1B_IW_20190315T195015_SHP_RTC20_G_gpuned_E650_HH.tif'\n",
    "#ProdID = 'hyp3-gamma'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bharati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_name = 'S1B_IW_SLC__1SSH_20190223T222639_20190223T222706_015079_01C2E9_1D63'\n",
    "tif_path = f'{tif_folder}/32743_OPERA_L2_RTC-S1B_IW_SLC__1SSH_20190223T222639_20190223T222706_015079_01C2E9_1D63_HH.tif'\n",
    "ProdID = 'rtc-opera-32743'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save products to folder\n",
    "savepath = os.path.join(data_folder,s1_name)\n",
    "os.makedirs(savepath, exist_ok=True)\n",
    "\n",
    "dates = s1_name.split('T')[0].split('_')[5]\n",
    "Year = dates[0:4]\n",
    "Month = dates[4:6]\n",
    "Day = dates[6:9]\n",
    "print(Year, Month, Day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading required file parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ProdID == 'pyrosar':\n",
    "    # fix projection in pyrosar tif not assigned correctly\n",
    "    assign_crs(tif_path, 3031)\n",
    "\n",
    "# get dif info\n",
    "with rasterio.open(tif_path) as ds:   \n",
    "    start_x = ds.transform[2]+0.5*ds.transform[0]\n",
    "    start_y = ds.transform[5]+0.5*ds.transform[4]\n",
    "    spacing_x = ds.transform[0]\n",
    "    spacing_y = ds.transform[4]\n",
    "    width = ds.profile['width']\n",
    "    height = ds.profile['height']\n",
    "    epsg_no = ds.crs.to_epsg()\n",
    "    b = ds.bounds \n",
    "print(epsg_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing RTC Image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(tif_path) as ds:\n",
    "    rtc = ds.read(1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "ax.set_title(tif_path)\n",
    "ax.imshow(20*np.log10(np.abs(rtc)), cmap='gray',interpolation=None, origin='upper')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Get Corner Reflector Data and Confirm RTC Coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.a Get Corner Reflector data from calval portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download corner reflector dataset from CEOS calval portal\n",
    "url = 'http://calvalportal.ceos.org/documents/10136/26472/CEOS-reference-targets.kml/be2807cf-2b33-45ca-932f-a91ddc0d2cb1'\n",
    "cr_filepath = os.path.join(data_folder,'CRS.kml')\n",
    "urlretrieve(url, cr_filepath)\n",
    "\n",
    "from fiona.drvsupport import supported_drivers\n",
    "supported_drivers['LIBKML'] = 'rw'\n",
    "\n",
    "gdf_list = []\n",
    "for layer in fiona.listlayers(cr_filepath):    \n",
    "    gdf = gpd.read_file(cr_filepath, driver='LIBKML', layer=layer)\n",
    "    gdf_list.append(gdf)\n",
    "\n",
    "df_cr = gpd.GeoDataFrame(pd.concat(gdf_list, ignore_index=True))\n",
    "df_cr['lon'] = df_cr.geometry.apply(lambda p: p.x if hasattr(p,'x') else np.nan)\n",
    "df_cr['lat'] = df_cr.geometry.apply(lambda p: p.y if hasattr(p,'y') else np.nan)\n",
    "print(f'entries: {len(df_cr)}')\n",
    "df_cr\n",
    "print('removing entries with no lat lon')\n",
    "df_cr = df_cr[~(df_cr['lon'].isna() | df_cr['lat'].isna())]\n",
    "print(f'entries: {len(df_cr)}')\n",
    "df_cr.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.b specify corner reflector data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specify_CRS = True\n",
    "cr_data = [\n",
    "    {\n",
    "        'Name':'Bharati Research Station (Antarctica)',\n",
    "        'shortname': 'Bharati',\n",
    "        'lat': -69.404787,\n",
    "        'lon': 76.190152,\n",
    "        'slen': 0.9,\n",
    "        'azm': 350, # unknown, set for descending filter below\n",
    "\n",
    "    },\n",
    "    {\n",
    "        'Name':'Maitri Research Station (Antarctica)',\n",
    "        'shortname': 'Maitri',\n",
    "        'lat': -70.767004,\n",
    "        'lon': 11.72366,\n",
    "        'slen': 0.9,\n",
    "        'azm': 100, # unknown, set for ascending filter below\n",
    "\n",
    "    },\n",
    "]\n",
    "if specify_CRS:\n",
    "    df = pd.DataFrame(cr_data)\n",
    "    df['geometry'] = df.apply(lambda x: geometry.Point(x.lon, x.lat), axis=1)\n",
    "    df_cr = gpd.GeoDataFrame(df, crs=\"EPSG:4326\", geometry='geometry')\n",
    "df_cr    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discovering which Corner Reflectors are within RTC coverage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkt_border = f'POLYGON(({b.left} {b.top},{b.right} {b.top},{b.right} {b.bottom},{b.left} {b.bottom},{b.left} {b.top}))'\n",
    "poly = shapely.wkt.loads(wkt_border)\n",
    "poly_4326 = transform_polygon(epsg_no, 4326, poly, always_xy=False)\n",
    "print(poly)\n",
    "print(poly_4326)\n",
    "\n",
    "#calculating the locations of CRs in SAR image\n",
    "UTMx = []\n",
    "UTMy = []\n",
    "xloc = []\n",
    "yloc = []\n",
    "xloc_float = []\n",
    "yloc_float = []\n",
    "_in = []\n",
    "\n",
    "df_cr_target_crs = df_cr.to_crs(epsg_no)\n",
    "\n",
    "# TODO bad pandas code, fix\n",
    "\n",
    "for idx, row in df_cr.iterrows():\n",
    "    \n",
    "    _Proj = Proj(CRS.from_epsg(epsg_no))\n",
    "    _x = df_cr_target_crs.iloc[idx].geometry.x\n",
    "    _y = df_cr_target_crs.iloc[idx].geometry.y\n",
    "    \n",
    "    if (np.isfinite(_x) and np.isfinite(_y)):\n",
    "        # coordinates not finite in utm\n",
    "    \n",
    "        #location of CRs in SLC image\n",
    "        _xloc = int(round((_x-start_x)/spacing_x))    \n",
    "        _yloc = int(round((_y-start_y)/spacing_y))\n",
    "        \n",
    "        UTMx.append(_x) \n",
    "        UTMy.append(_y)\n",
    "        xloc.append(_xloc)\n",
    "        yloc.append(_yloc)\n",
    "        xloc_float.append((_x-start_x)/spacing_x)\n",
    "        yloc_float.append((_y-start_y)/spacing_y)\n",
    "        _in.append(poly.contains(geometry.Point(_x, _y)))\n",
    "\n",
    "    else:\n",
    "        UTMx.append(np.nan) \n",
    "        UTMy.append(np.nan)\n",
    "        xloc.append(np.nan) # loc in image\n",
    "        yloc.append(np.nan)\n",
    "        xloc_float.append(np.nan)\n",
    "        yloc_float.append(np.nan)\n",
    "        _in.append(np.nan)\n",
    "    \n",
    "df_cr['UTMx'] = UTMx\n",
    "df_cr['UTMy'] = UTMy\n",
    "df_cr['xloc'] = xloc\n",
    "df_cr['yloc'] = yloc\n",
    "df_cr['xloc_float'] = xloc_float\n",
    "df_cr['yloc_float'] = yloc_float\n",
    "df_cr['inPoly'] = _in\n",
    "\n",
    "# exclude non valid crs where values in UTM are not valid\n",
    "df_cr_roi = df_cr[~df_cr['UTMx'].isna()]\n",
    "\n",
    "#checking whether CRs are in RTC coverage. Including only CRs within RTC image\n",
    "df_cr_roi = df_cr_roi[df_cr_roi['inPoly']==True]\n",
    "df_cr_roi.drop('inPoly', axis=1, inplace=True)\n",
    "df_cr_roi = df_cr_roi.reset_index(drop=True)\n",
    "# get the cr size from the description\n",
    "if 'slen' not in list(df_cr_roi):\n",
    "    df_cr_roi['slen'] = (df_cr_roi.Name.apply(\n",
    "        lambda x : float(re.findall(\"[-+]?(?:\\d*\\.*\\d+) m\", x)[0].split('m')[0])))\n",
    "# add a shortname\n",
    "if 'shortname' not in list(df_cr_roi):\n",
    "    df_cr_roi['shortname'] = df_cr_roi['Name'].apply(lambda x : x.split('(')[0])\n",
    "# set cr direction if not exist\n",
    "if 'azm' not in list(df_cr_roi):\n",
    "    df_cr_roi['azm'] = 100 # for ascending pass TODO this is wrong\n",
    "df_cr_roi.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing** CRs on RTC Image. We color code by reflector size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Displaying RTC image\n",
    "buffer = 50\n",
    "minX = df_cr_roi['xloc'].min() - buffer\n",
    "maxX = df_cr_roi['xloc'].max() + buffer\n",
    "minY = df_cr_roi['yloc'].min() - buffer\n",
    "maxY = df_cr_roi['yloc'].max() + buffer\n",
    "\n",
    "scale_ = 1.0\n",
    "exp_ = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    "cax = ax.imshow(scale_*(np.abs(rtc))**exp_, cmap='gray',interpolation='bilinear', vmin=0.3, vmax=1.7, origin='upper')\n",
    "ax.set_xlim(minX,maxX)\n",
    "ax.set_ylim(minY,maxY)\n",
    "ax.axis('off')\n",
    "\n",
    "for sl in pd.unique(df_cr_roi.slen):\n",
    "    xx = df_cr_roi.loc[df_cr_roi['slen']==sl]['xloc']\n",
    "    yy = df_cr_roi.loc[df_cr_roi['slen']==sl]['yloc']\n",
    "    ID = df_cr_roi.loc[df_cr_roi['slen']==sl]['shortname']\n",
    "    \n",
    "    if sl == 2.4384:\n",
    "        color=[0.7, 0.7, 0.7]\n",
    "    elif sl == 4.8:\n",
    "        color=[0.7, 0.7, 0.7]\n",
    "    elif sl == 2.8:\n",
    "        color=[0.7, 0.7, 0.7]\n",
    "    else:\n",
    "        color=[0.7, 0.7, 0.7]\n",
    "    \n",
    "    ax.scatter(xx,yy,color=color,marker=\"o\",facecolor='none',lw=1)\n",
    "    for _ID,_xx,_yy in zip(ID,xx,yy):\n",
    "\n",
    "        ax.annotate(_ID, (_xx+buffer, _yy-buffer), fontsize=10,color=[0.7, 0.7, 0.7])\n",
    "\n",
    "ax.set_aspect(1)\n",
    "plt.gca().invert_yaxis()\n",
    "fig_path = os.path.join(savepath, f'{s1_name}_S1_geoRTC_CRs.png')\n",
    "fig.savefig(fig_path,dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Remove Corner Reflectors Facing away from the look direction of the S1 Acquisition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = asf_search.granule_search(s1_name)\n",
    "flight_direction = results[0].properties['flightDirection']\n",
    "flight_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting CRs according to orbit direction\n",
    "if flight_direction == 'DESCENDING':\n",
    "    # descending\n",
    "    df_filter = df_cr_roi[df_cr_roi['azm']>340].reset_index(drop=True)\n",
    "    #only east-looking CRs (for right-looking descending)\n",
    "else:\n",
    "    # ascending\n",
    "    df_filter = df_cr_roi[df_cr_roi['azm']<200].reset_index(drop=True)    \n",
    "    #only west-looking CRs (for right-looking ascending)\n",
    "\n",
    "df_filter = df_filter.loc[df_filter['slen']>0.8].reset_index(drop=True)   #excluding SWOT CRs (0.7 m as a side length)\n",
    "df_filter.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Calculate Absolute Geolocation Error in Easting and Northing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lorentzian2d(x, y, amplitude=1., centerx=0., centery=0., sigmax=1., sigmay=1.,\n",
    "                 rotation=0):\n",
    "    \"\"\"Return a two dimensional lorentzian.\n",
    "\n",
    "    The maximum of the peak occurs at ``centerx`` and ``centery``\n",
    "    with widths ``sigmax`` and ``sigmay`` in the x and y directions\n",
    "    respectively. The peak can be rotated by choosing the value of ``rotation``\n",
    "    in radians.\n",
    "    \"\"\"\n",
    "    xp = (x - centerx)*np.cos(rotation) - (y - centery)*np.sin(rotation)\n",
    "    yp = (x - centerx)*np.sin(rotation) + (y - centery)*np.cos(rotation)\n",
    "    R = (xp/sigmax)**2 + (yp/sigmay)**2\n",
    "\n",
    "    return 2*amplitude*lorentzian(R)/(np.pi*sigmax*sigmay)\n",
    "\n",
    "def gaussfit(x, y, A, x0, y0, sigma_x, sigma_y, theta):\n",
    "    theta = np.radians(theta)\n",
    "    sigx2 = sigma_x**2; sigy2 = sigma_y**2\n",
    "    a = np.cos(theta)**2/(2*sigx2) + np.sin(theta)**2/(2*sigy2)\n",
    "    b = np.sin(theta)**2/(2*sigx2) + np.cos(theta)**2/(2*sigy2)\n",
    "    c = np.sin(2*theta)/(4*sigx2) - np.sin(2*theta)/(4*sigy2)\n",
    "    \n",
    "    expo = -a*(x-x0)**2 - b*(y-y0)**2 - 2*c*(x-x0)*(y-y0)\n",
    "    return A*np.exp(expo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_filter = df_filter.iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpeak = []\n",
    "ypeak = []\n",
    "snr = []\n",
    "\n",
    "ovsFactor=32\n",
    "\n",
    "for ID, xoff, yoff in zip(df_filter['shortname'],df_filter['xloc'],df_filter['yloc']):\n",
    "    # crop a patch of 10*10 with center at the calculated CR position\n",
    "    pxbuff = 5\n",
    "    pybuff = 5\n",
    "    cropcslc = rtc[(yoff-pybuff):(yoff+pybuff),(xoff-pxbuff):(xoff+pxbuff)]\n",
    "    \n",
    "    if np.isnan(np.mean(cropcslc))!=True:\n",
    "       # _snr = get_snr_peak(cropcslc)\n",
    "\n",
    "        # find the peak amplitude in the 10*10 patch\n",
    "        yind,xind = np.unravel_index(np.argmax(np.abs(cropcslc), axis=None), cropcslc.shape)\n",
    "    \n",
    "        # give a warning if the peak and the calculated postion are too far\n",
    "        dyind = yind-pybuff; dxind = xind-pxbuff\n",
    "        dist = math.sqrt(dyind**2+dxind**2)\n",
    "        if dist > 2.0:\n",
    "            warn_str = f'the most bright pixel and the xloc is too far for CR {ID}: {dist:.2f} m'\n",
    "            warnings.warn(warn_str)\n",
    "    \n",
    "        plt.rcParams.update({'font.size': 14})\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(15, 7))\n",
    "        ax[0].imshow(np.abs(cropcslc), cmap='gray',interpolation=None, origin='upper')\n",
    "        ax[0].plot(xind,yind,'r+')\n",
    "        ax[0].set_title(f'Corner Reflector ID: {ID}', size=8)\n",
    "    \n",
    "        # crop a patch of 32*32 but with its center at the peak\n",
    "        xbuff = 32\n",
    "        ybuff = 32\n",
    "        ycrop = np.arange(yoff+dyind-ybuff,yoff+dyind+ybuff)\n",
    "        xcrop = np.arange(xoff+dxind-xbuff,xoff+dxind+xbuff)\n",
    "        cropcslc = rtc[ycrop,:][:,xcrop]\n",
    "\n",
    "        # Oversample slc\n",
    "        cropcslc_ovs,ycrop_ovs,xcrop_ovs = oversample_slc(cropcslc,sampling=ovsFactor,y=ycrop,x=xcrop)\n",
    "\n",
    "        numpix = 2\n",
    "    \n",
    "        # find the peak amplitude again in a 2 x 2 patch, it correspond to \n",
    "        # (2*ovsFactor) x (2*ovsFactor) in oversampled slc\n",
    "        yoff2 = int(cropcslc_ovs.shape[0]/2)\n",
    "        xoff2 = int(cropcslc_ovs.shape[1]/2)\n",
    "        cropcslc2 = cropcslc_ovs[yoff2-numpix*ovsFactor:yoff2+numpix*ovsFactor,\n",
    "                               xoff2-numpix*ovsFactor:xoff2+numpix*ovsFactor]\n",
    "        yind2,xind2 = np.unravel_index(np.argmax(abs(cropcslc2), axis=None), cropcslc2.shape)\n",
    "        dyind2 = yind2-numpix*ovsFactor; dxind2 = xind2-numpix*ovsFactor\n",
    "    \n",
    "        N = numpix*2* ovsFactor\n",
    "        x = np.linspace(0,numpix*2*ovsFactor-1,N)\n",
    "        y = np.linspace(0,numpix*2*ovsFactor-1,N)\n",
    "        Xg, Yg = np.meshgrid(x, y)\n",
    "        fmodel = Model(gaussfit, independent_vars=('x','y'))\n",
    "        theta = 0.1  # deg\n",
    "        x0 = numpix* ovsFactor\n",
    "        y0 = numpix* ovsFactor\n",
    "        sigx = 2\n",
    "        sigy = 5\n",
    "        A = np.max(np.abs(cropcslc2))\n",
    "\n",
    "        result = fmodel.fit(np.abs(cropcslc2), x=Xg, y=Yg, A=A, x0=x0, y0=y0, sigma_x=sigx, sigma_y=sigy, theta=theta)\n",
    "        fit = fmodel.func(Xg, Yg, **result.best_values)\n",
    "    \n",
    "        dyind3 = result.best_values['y0']-numpix*ovsFactor; dxind3 = result.best_values['x0']-numpix*ovsFactor\n",
    "    \n",
    "        ax[1].imshow(np.abs(cropcslc2), cmap='gray',interpolation=None, origin='upper')\n",
    "        ax[1].plot(xind2,yind2,'r+')\n",
    "        ax[1].plot(result.best_values['x0'],result.best_values['y0'],'b+')\n",
    "        ax[1].set_title(f'Oversampled Corner Reflector ID: {ID}', size=8)\n",
    "    \n",
    "        ax[2].imshow(np.abs(fit), cmap='gray',interpolation=None, origin='upper')\n",
    "        ax[2].plot(xind2,yind2,'r+')\n",
    "        ax[2].plot(result.best_values['x0'],result.best_values['y0'],'b+')\n",
    "        ax[2].set_title(f'Oversampled Corner Reflector ID: {ID}', size=8)\n",
    "        fig_path = os.path.join(savepath, f'{s1_name}_{ID}_CR.png')\n",
    "        plt.savefig(fig_path)\n",
    "    \n",
    "        # crop a patch of 3x3 oversampled patch with center at the peak\n",
    "        cropcslc3 = cropcslc_ovs[yoff2+dyind2-1:yoff2+dyind2+2,xoff2+dxind2-1:xoff2+dxind2+2]\n",
    "        ycrop2 = ycrop_ovs[yoff2+dyind2-1:yoff2+dyind2+2]\n",
    "        xcrop2 = xcrop_ovs[xoff2+dxind2-1:xoff2+dxind2+2]\n",
    "        xxcrop2,yycrop2 = np.meshgrid(xcrop2,ycrop2)\n",
    "        xxcrop2_f = xxcrop2.flatten()\n",
    "        yycrop2_f = yycrop2.flatten()\n",
    "        cropcslc2_f = cropcslc3.flatten()\n",
    "\n",
    "        # Check if pixel values in a patch are non-NaN\n",
    "        valid = ~(np.isnan(cropcslc2_f))\n",
    "        count_valid = np.count_nonzero(valid)\n",
    "\n",
    "        if count_valid == 0:\n",
    "            _ypeak, _xpeak = [np.nan, np.nan]\n",
    "\n",
    "        else:\n",
    "            _ypeak,_xpeak = findCR(np.abs(cropcslc2_f[valid]),yycrop2_f[valid],xxcrop2_f[valid],\n",
    "                                x_bound=[xcrop2[0],xcrop2[-1]],y_bound=[ycrop2[0],ycrop2[-1]],method=\"para\")\n",
    "\n",
    "        #xpeak.append(_xpeak)\n",
    "        #ypeak.append(_ypeak)\n",
    "        #xpeak.append(xoff+dxind+dxind2/ovsFactor)\n",
    "        #ypeak.append(yoff+dyind+dyind2/ovsFactor)\n",
    "        xpeak.append(xoff+dxind+dxind3/ovsFactor)\n",
    "        ypeak.append(yoff+dyind+dyind3/ovsFactor)\n",
    "        #snr.append(_snr)\n",
    "    else:\n",
    "        xpeak.append(np.nan)\n",
    "        ypeak.append(np.nan)\n",
    "    \n",
    "df_filter['xloc_CR'] = xpeak\n",
    "df_filter['yloc_CR'] = ypeak\n",
    "#df_filter['snr'] = snr\n",
    "df_filter.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing CR Location Measurements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_filter = df_filter.dropna().reset_index(drop=True)\n",
    "df_filter.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Uncomment this Line to Drop CRs that were Poorly Identified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Calculating Absolute Geolocation Numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#absloute geolocation error in range and azimuth\n",
    "ALE_Rg = (df_filter['xloc_CR'] -  df_filter['xloc_float']) * spacing_x\n",
    "ALE_Az = (df_filter['yloc_CR'] - df_filter['yloc_float']) * spacing_y\n",
    "\n",
    "test_Rg = ((df_filter['xloc_float'] % 1.0)-0.5)\n",
    "test_Az = -((df_filter['yloc_float'] % 1.0)-0.5)\n",
    "\n",
    "test_Rg = ((df_filter['xloc']-df_filter['xloc_float']))\n",
    "test_Az = -((df_filter['yloc']-df_filter['yloc_float']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALE_Az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALE_Rg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(test_Az**2 + test_Rg**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Removing Corner Reflectors that are near the Edge of the Pixel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we cannot interpolate into the pixel, corner reflectors that sit near the edge of the pixel can bias our offset estimate. Therefore, we are removing corner reflectors near pixel edges before we analyze summary statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subpix = np.sqrt(test_Az**2 + test_Rg**2)\n",
    "keepind = []\n",
    "for idx, row in subpix.items():\n",
    "    if subpix[idx] <=0.55:\n",
    "        keepind.append(idx)\n",
    "print(keepind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Plot Absolute Geolocation Error in Easting and Northing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "requirement = plt.Rectangle((-3.0,-3.0), 6.0, 6.0, fill=False, edgecolor='grey', label='Requirement')\n",
    "ax.add_patch(requirement)\n",
    "#sc = ax.scatter(ALE_Rg, ALE_Az, s=200, c=df_filter['slen'], alpha=0.6, marker='o')\n",
    "sc = ax.scatter(ALE_Rg[keepind], ALE_Az[keepind], s=100, c='k', alpha=0.6, marker='o')\n",
    "#ax.legend(*sc.legend_elements(),facecolor='lightgray')\n",
    "#ax.get_legend().set_title('side length (m)')\n",
    "\n",
    "for ii, txt in enumerate(df_filter.iloc[keepind,0]):\n",
    "    shortname = df_filter.iloc[keepind[ii]].shortname\n",
    "    ax.annotate(shortname, (ALE_Rg[keepind[ii]],\n",
    "                            ALE_Az[keepind[ii]]), \n",
    "                            color='black',xytext=(0, 5), \n",
    "                            textcoords='offset points',\n",
    "                            fontsize='8')   #putting IDs in each CR\n",
    "    \n",
    "ax.grid(True)\n",
    "ax.set_xlim(-30,30)\n",
    "ax.set_ylim(-30,30)\n",
    "ax.axhline(0, color='black')\n",
    "ax.axvline(0, color='black')\n",
    "\n",
    "#np.std(data, ddof=1) / np.sqrt(np.size(data))\n",
    "\n",
    "ax.set_title(f'Easting: {np.round(np.nanmean(ALE_Rg[keepind]), 3)} +/- {np.round(np.nanstd(ALE_Rg[keepind]) / np.sqrt(np.size(ALE_Rg[keepind])),3)} m, \\\n",
    "    Northing: {np.round(np.nanmean(ALE_Az[keepind]),3)}, +/- {np.round(np.nanstd(ALE_Az[keepind]) / np.sqrt(np.size(ALE_Az[keepind])),3)} m')\n",
    "ax.set_xlabel('Easting error (m)')\n",
    "ax.set_ylabel('Northing error (m)')\n",
    "fig.suptitle('Absolute Geolocation Error')\n",
    "\n",
    "# plt.errorbar(np.round(np.nanmean(ALE_Rg[keepind]), 3), \n",
    "#              np.round(np.nanmean(ALE_Az[keepind]),3),\n",
    "#              xerr=np.round(np.nanstd(ALE_Rg[keepind]) / np.sqrt(np.size(ALE_Rg[keepind])),3), \n",
    "#              yerr=np.round(np.nanstd(ALE_Az[keepind]) / np.sqrt(np.size(ALE_Az[keepind])),3),\n",
    "#              barsabove=True, capsize=8, capthick=2, fmt='ro', linewidth=2, markersize=10)\n",
    "\n",
    "output = f\"{s1_name}_GeolocationPLOT.png\"\n",
    "fig_path = os.path.join(savepath, output)\n",
    "plt.savefig(fig_path, dpi=300, transparent='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s1_name)\n",
    "print(np.round(np.nanmean(ALE_Rg[keepind]), 3))\n",
    "print(np.round(np.nanstd(ALE_Rg[keepind]) / np.sqrt(np.size(ALE_Rg[keepind])),3))\n",
    "print(np.round(np.nanmean(ALE_Az[keepind]),3))\n",
    "print(np.round(np.nanstd(ALE_Az[keepind]) / np.sqrt(np.size(ALE_Az[keepind])),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting ALE\n",
    "\n",
    "#msize = (df_filter['CRZscrores'] - np.min(df_filter['CRZscrores']) + 0.000001) * 100.0\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "requirement = plt.Rectangle((-3.0,-3.0), 6.0, 6.0, fill=False, edgecolor='grey', label='Requirement')\n",
    "ax.add_patch(requirement)\n",
    "#sc = ax.scatter(ALE_Rg, ALE_Az, s=200, c=df_filter['slen'], alpha=0.6, marker='o')\n",
    "sc = ax.scatter(test_Rg, test_Az, s=100, c='k', alpha=0.6, marker='o')\n",
    "\n",
    "\n",
    "for ii, txt in enumerate(df_filter.iloc[:,0]):\n",
    "    shortname = df_filter.iloc[ii].shortname\n",
    "    ax.annotate(shortname, \n",
    "                (test_Rg[ii],\n",
    "                 test_Az[ii]), \n",
    "                 color='black',xytext=(0, 5), \n",
    "                 textcoords='offset points',\n",
    "                 fontsize=8)   #putting IDs in each CR\n",
    "    \n",
    "ax.grid(True)\n",
    "ax.set_xlim(-1.25,1.25)\n",
    "ax.set_ylim(-1.25,1.25)\n",
    "ax.axhline(0, color='black')\n",
    "ax.axvline(0, color='black')\n",
    "\n",
    "ax.set_title(f'Easting: {np.round(np.nanmean(test_Rg), 3)} +/- {np.round(np.nanstd(test_Rg) / np.sqrt(np.size(test_Rg)),3)} m, \\\n",
    "    Northing: {np.round(np.nanmean(test_Az),3)}, +/- {np.round(np.nanstd(test_Az) / np.sqrt(np.size(test_Az)),3)} m')\n",
    "ax.set_xlabel('Easting error (m)')\n",
    "ax.set_ylabel('Northing error (m)')\n",
    "fig.suptitle('Fractional Offset from Pixel Center')\n",
    "\n",
    "plt.errorbar(np.round(np.nanmean(test_Rg), 3), np.round(np.nanmean(test_Az),3),\\\n",
    "             xerr=np.round(np.nanstd(test_Rg) / np.sqrt(np.size(test_Rg)),3), yerr=np.round(np.nanstd(test_Az) / np.sqrt(np.size(test_Az)),3), \\\n",
    "             barsabove=True, capsize=8, capthick=2, fmt='ro', linewidth=2, markersize=10)\n",
    "\n",
    "output = f\"{s1_name}_FracOffset.png\"\n",
    "fig_path = os.path.join(savepath, output)\n",
    "plt.savefig(fig_path, dpi=300, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Write Results into a CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALE_csv = os.path.join(savepath,f\"{s1_name}_ALE30-Results.csv\")\n",
    "\n",
    "fields = [\n",
    "    \"ProdID\"\n",
    "    \"Granule\", \n",
    "    \"Year\", \n",
    "    \"Month\", \n",
    "    \"Day\", \n",
    "    \"Easting_Bias\", \n",
    "    \"sig_Easting_Bias\", \n",
    "    \"Northing_Bias\", \n",
    "    \"sig_Northing_Bias\"]\n",
    "\n",
    "row = [\n",
    "    ProdID,\n",
    "    s1_name, \n",
    "    Year, \n",
    "    Month, \n",
    "    Day,  \n",
    "    np.round(np.nanmean(ALE_Rg[keepind]), 3), \n",
    "    np.round(np.nanstd(ALE_Rg[keepind]) / np.sqrt(np.size(ALE_Rg[keepind])),3),\n",
    "    np.round(np.nanmean(ALE_Az[keepind]), 3), \n",
    "    np.round(np.nanstd(ALE_Az[keepind]) / np.sqrt(np.size(ALE_Az[keepind])),3)\n",
    "    ]\n",
    "\n",
    "if not os.path.exists(ALE_csv):\n",
    "    with open(ALE_csv, 'w') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(fields)\n",
    "        csvwriter.writerow(row)\n",
    "else:\n",
    "    with open(ALE_csv, 'r') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        s1_names = [c[0] for c in list(csvreader)]\n",
    "    if s1_name not in s1_names:\n",
    "        with open(ALE_csv, 'a') as csvfile:\n",
    "            csvwriter = csv.writer(csvfile)\n",
    "            csvwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALE_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*ALE_OPERA_RTC.ipynb - Version 2.0.0 - April 2023*\n",
    "\n",
    "*Change log*\n",
    "\n",
    "- Made CR discovery more robust\n",
    "- Added average visualization in geolocation plot\n",
    "- Made formatting changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compare-rtc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
